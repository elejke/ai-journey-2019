{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pymorphy2\n",
    "from pymorphy2.units.by_lookup import DictionaryAnalyzer\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "slovarnie_slova = pd.read_csv(\"../models/dictionaries/slovarnie_slova.txt\", header=None).rename({0: \"word\"}, axis=1)\n",
    "stress_dict = pd.read_csv(\"../models/dictionaries/orfoepicheskiy_automatic_gde_udarenie_rf.txt\", header=None).rename({0: \"word\"}, axis=1)\n",
    "with open(\"/Users/edgy/Downloads/task_9_dixt_drop_ya.pickle\", \"rb\") as f:\n",
    "    exact_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solver_9(task, testing=False):\n",
    "    def is_unverifiable(w):\n",
    "        for w2 in slovarnie_slova.word:\n",
    "            if re.match(re.sub(r\"\\.\\.\", \".\", w), w2):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def is_stressed(w, pos):\n",
    "        if len(w) == pos:\n",
    "            w = w[:pos] + w[pos].upper()\n",
    "        else:\n",
    "            w = w[:pos] + w[pos].upper() + w[pos+1:]\n",
    "        return w in stress_dict.word.values\n",
    "\n",
    "    def word_exists(w):\n",
    "        analysis = morph.parse(w)\n",
    "        if (analysis[0].methods_stack[0][0].__class__.__name__ == \"DictionaryAnalyzer\") and (analysis[0].methods_stack[0][1] == w):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def possible_variants(w):\n",
    "        amount = 0\n",
    "        for candidate in \"аоеиы\":\n",
    "            w_n = re.sub(r\"\\.\\.\", candidate, w)\n",
    "            analysis = morph.parse(w_n)\n",
    "            if (analysis[0].methods_stack[0][0].__class__.__name__ == \"DictionaryAnalyzer\") and (analysis[0].methods_stack[0][1] == w_n):\n",
    "                amount += 1\n",
    "        if amount == 0:\n",
    "            amount = 1\n",
    "        return amount\n",
    "\n",
    "    def is_alternant(w):\n",
    "        #зависящие от конечной согласной корня\n",
    "        patterns_1 = [\n",
    "            (r\"[а-я]*р\\.\\.(ст|щ)[а-я]*\", \"а\"),\n",
    "            (r\"[а-я]*р\\.\\.с[а-су-я]*\", \"о\"),\n",
    "            (r\"[а-я]*л\\.\\.г[а-я]*\", \"а\"),\n",
    "            (r\"[а-я]*л\\.\\.ж[а-я]*\", \"о\"),\n",
    "            (r\"[а-я]*ск\\.\\.к[а-я]*\", \"а\"),\n",
    "            (r\"[а-я]*ск\\.\\.ч[а-я]*\", \"о\"),\n",
    "        ]\n",
    "        #зависящие от суффикса \"а\" после корня\n",
    "        patterns_2 = [\n",
    "            (r\"[а-я]*(б|д|м|п|т)\\.\\.ра[а-я]*\", \"и\"),\n",
    "            (r\"[а-я]*бл\\.\\.ста[а-я]*\", \"и\"),\n",
    "            (r\"[а-я]*ж\\.\\.га[а-я]*\", \"и\"),\n",
    "            (r\"[а-я]*ст\\.\\.ла[а-я]*\", \"и\"),\n",
    "            (r\"[а-я]*ч\\.\\.та[а-я]*\", \"и\"),\n",
    "            (r\"[а-я]*к\\.\\.са[а-я]*\", \"а\"),\n",
    "            (r\"[а-я]*(б|д|м|п|т)\\.\\.р[б-я]*\", \"е\"),\n",
    "            (r\"[а-я]*бл\\.\\.ст[б-я]*\", \"е\"),\n",
    "            (r\"[а-я]*ж\\.\\.г[б-я]*\", \"е\"),\n",
    "            (r\"[а-я]*ст\\.\\.л[б-я]*\", \"е\"),\n",
    "            (r\"[а-я]*ч\\.\\.т[б-я]*\", \"е\"),\n",
    "            (r\"[а-я]*к\\.\\.с[б-я]*\", \"о\"),\n",
    "        ]\n",
    "        #зависящие от ударения (плов-плав хз почему тут, всегда пишется \"а\" кроме исключений)\n",
    "        patterns_3a = [\n",
    "            (r\"[а-я]*з\\.\\.р[а-я]*\", \"оа\"),\n",
    "            (r\"[а-я]*г\\.\\.р[а-я]*\", \"ао\"),\n",
    "            (r\"[а-я]*тв\\.\\.р[а-нп-я]+\", \"ао\"),\n",
    "        ]\n",
    "        patterns_3b = [\n",
    "            (r\"[а-я]*пл\\.\\.в[а-я]*\", \"оа\"),\n",
    "        ]\n",
    "        #зависящие от лексического значения\n",
    "        patterns_4 = [\n",
    "            (r\"[а-я]*м\\.\\.к[а-я]*\", \"оа\"),\n",
    "            (r\"[а-я]*р\\.\\.вн[а-я]*\", \"оа\"),\n",
    "        ]\n",
    "\n",
    "        exceptions = [\n",
    "            \"росток\", \"ростов\", \"ростислав\", \"ростовщик\",\n",
    "            \"отрасль\", \"скачок\", \"скачу\", \"сочетать\", \"сочетание\",\n",
    "            \"чета\", \"зоревать\", \"зорянка\", \"пловец\", \"пловчиха\",\n",
    "            \"плывуны\", \"уровень\", \"ровесник\", \"равнина\", \"равняйсь\", \n",
    "            \"равнение \",\n",
    "        ]\n",
    "        w = w.lower()\n",
    "        pos_space = re.search(r\"\\.\", w).span()[0]\n",
    "        for p in patterns_1:\n",
    "            if re.match(p[0], w):\n",
    "                for p_i in p[1]:\n",
    "                    filled_w = re.sub(r\"\\.\\.\", p_i, w)\n",
    "                    if word_exists(filled_w):\n",
    "                        stressed = is_stressed(filled_w, pos_space)\n",
    "                        return True, 1, filled_w, pos_space, stressed\n",
    "        for p in patterns_2:\n",
    "            if re.match(p[0], w):\n",
    "                for p_i in p[1]:\n",
    "                    filled_w = re.sub(r\"\\.\\.\", p_i, w)\n",
    "                    if word_exists(filled_w):\n",
    "                        stressed = is_stressed(filled_w, pos_space)\n",
    "                        return True, 2, filled_w, pos_space, stressed\n",
    "        for p in patterns_4:\n",
    "            if re.match(p[0], w):\n",
    "                for p_i in p[1]:\n",
    "                    filled_w = re.sub(r\"\\.\\.\", p_i, w)\n",
    "                    if word_exists(filled_w):\n",
    "                        stressed = is_stressed(filled_w, pos_space)\n",
    "                        return True, 4, filled_w, pos_space, stressed\n",
    "        for p in patterns_3a:\n",
    "            if re.match(p[0], w):\n",
    "                for q, p_i in enumerate(p[1]):\n",
    "                    filled_w = re.sub(r\"\\.\\.\", p_i, w)\n",
    "                    if word_exists(filled_w):\n",
    "                        stress_ind = is_stressed(filled_w, pos_space)\n",
    "                        if (stress_ind) and (q == 0):\n",
    "                            return True, 3, filled_w, pos_space, True\n",
    "                        if (q == 1) and (not stress_ind):\n",
    "                            return True, 3, filled_w, pos_space, False\n",
    "        for p in patterns_3b:\n",
    "            if re.match(p[0], w):\n",
    "                for p_i in p[1]:\n",
    "                    filled_w = re.sub(r\"\\.\\.\", p_i, w)\n",
    "                    if word_exists(filled_w):\n",
    "                        stressed = is_stressed(filled_w, pos_space)\n",
    "                        return True, 3, filled_w, pos_space, stressed\n",
    "        return False, None, None, pos_space, None\n",
    "\n",
    "    words = np.array([re.split(r\", \", t[\"text\"]) for t in task[\"question\"][\"choices\"]])\n",
    "    #обрезаем скобки\n",
    "#     words = [[re.sub(\"\\([а-я ]+\\)\", \"\", t2).strip() for t2 in t1] for t1 in words]\n",
    "    words = [[re.sub(r\"[0-9]+\\)\", \"\", re.sub(r\"\\([а-я ]+\\)\", \"\", t2)).strip() for t2 in t1] for t1 in words]\n",
    "    #в зависимости от числа слов в каждом варианте, мы ожидаем разное число верных ответов\n",
    "    num_answers = 2\n",
    "    if len(words[0]) == 1:\n",
    "        num_answers = 1\n",
    "    #определяем какой тип нужно искать\n",
    "    if \"чередующ\" in task[\"text\"]:\n",
    "        task_type = 0\n",
    "    elif \"непровер\" in task[\"text\"]:\n",
    "        task_type = 1\n",
    "    else:\n",
    "        task_type = 2\n",
    "    alt_labels = [[is_alternant(t2) for t2 in t1] for t1 in words]\n",
    "    unver_labels = [[is_unverifiable(t2) for t2 in t1] for t1 in words]\n",
    "    possible_ways = [[possible_variants(t2) for t2 in t1] for t1 in words]\n",
    "    scores = np.zeros((len(words), len(words[0]), 3))\n",
    "    for i in range(scores.shape[0]):\n",
    "        for j in range(scores.shape[1]):\n",
    "            scores[i, j, 0] = 0\n",
    "            scores[i, j, 1] = unver_labels[i][j]\n",
    "            if alt_labels[i][j][0]:\n",
    "                scores[i, j, 0] = alt_labels[i][j][0]\n",
    "            scores[i, j, 2] = 1 - scores[i, j, 0] - 10 * scores[i, j, 1] * (possible_ways[i][j]-1)\n",
    "    if testing: print(scores)\n",
    "    agg_scores = scores.mean(axis=1)\n",
    "    if testing: print(agg_scores)\n",
    "    agg_scores = agg_scores[:, task_type]\n",
    "    if testing: print(agg_scores)\n",
    "    max_score = agg_scores.max()\n",
    "    second_value = agg_scores[agg_scores.argsort()[-2]]\n",
    "    answer_numbers = np.arange(len(agg_scores))[agg_scores==max_score]\n",
    "    if (len(answer_numbers) < 2) and (second_value > 0):\n",
    "        answer_numbers = np.concatenate([answer_numbers,\n",
    "                                         np.arange(len(agg_scores))[agg_scores==second_value]])\n",
    "    answer_numbers = answer_numbers[:2]\n",
    "#     answer_numbers = agg_scores.argsort()[2:]\n",
    "    answer_numbers += 1\n",
    "    answer_numbers = [str(t) for t in answer_numbers]\n",
    "    return answer_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/edgy/Downloads/task_9/T7009.json\", \"r\") as f:\n",
    "    js = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tasks': [{'id': '9',\n",
       "   'text': 'Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная проверяемая гласная корня.',\n",
       "   'meta': {'language': 'ru', 'source': 'yandex_test'},\n",
       "   'attachments': [],\n",
       "   'solution': {'correct_variants': [['4', '5'], ['5', '4']]},\n",
       "   'score': 1,\n",
       "   'question': {'type': 'multiple_choice',\n",
       "    'min_choices': 1,\n",
       "    'choices': [{'id': '1',\n",
       "      'text': 'зас..вать (поля), разв..вающиеся (страны), попл..вок'},\n",
       "     {'id': '2', 'text': 'зас..дание, прож..вать (в деревне), сл..гаемые'},\n",
       "     {'id': '3', 'text': 'озл..бление, погл..щённый, преп..рательства'},\n",
       "     {'id': '4', 'text': 'с..мволика, зат..вать (драку), кол..бание'},\n",
       "     {'id': '5', 'text': 'к..робочка, под..конник, впеч..тление'}]}}]}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[   0.      0.   -100.  ]\n",
      "  [   0.      0.   -100.  ]\n",
      "  [   0.      0.   -100.  ]]\n",
      "\n",
      " [[   0.      0.      0.9 ]\n",
      "  [   0.      0.      0.9 ]\n",
      "  [   0.9     0.      0.45]]\n",
      "\n",
      " [[   0.      0.      0.9 ]\n",
      "  [   0.      0.      1.  ]\n",
      "  [   0.9     0.      0.45]]\n",
      "\n",
      " [[   0.      0.      0.9 ]\n",
      "  [   0.      0.      0.9 ]\n",
      "  [   0.      0.      0.9 ]]\n",
      "\n",
      " [[   0.      0.      0.9 ]\n",
      "  [   0.      0.9     0.45]\n",
      "  [   0.      0.9     0.45]]]\n",
      "[[   0.            0.         -100.        ]\n",
      " [   0.3           0.            0.75      ]\n",
      " [   0.3           0.            0.78333333]\n",
      " [   0.            0.            0.9       ]\n",
      " [   0.            0.6           0.6       ]]\n",
      "[-100.            0.75          0.78333333    0.9           0.6       ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['4', '3']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver_9(js[\"tasks\"][0], testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task T5432\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная проверяемая гласная корня.\n",
      "True answer: {'5', '2'}\n",
      "Predicted answer: {'3', '2'}\n",
      "Task T7008\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная проверяемая гласная корня.\n",
      "True answer: {'1', '5'}\n",
      "Predicted answer: {'1', '3'}\n",
      "Task T8538\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена чередующаяся гласная корня.\n",
      "True answer: {'5', '2'}\n",
      "Predicted answer: {'3', '2'}\n",
      "Task T3749\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная проверяемая гласная корня.\n",
      "True answer: {'3', '4', '2'}\n",
      "Predicted answer: {'1', '3'}\n",
      "Task T7012\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная проверяемая гласная корня.\n",
      "True answer: {'1', '4'}\n",
      "Predicted answer: {'1', '3'}\n",
      "Task T7013\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная непроверяемая гласная корня.\n",
      "True answer: {'5', '3'}\n",
      "Predicted answer: {'1', '2'}\n",
      "Task T8470\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная непроверяемая гласная корня.\n",
      "True answer: {'1', '4'}\n",
      "Predicted answer: {'1', '3'}\n",
      "Task T7005\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня.\n",
      "True answer: {'3', '5', '2'}\n",
      "Predicted answer: {'3', '2'}\n",
      "Task T7639\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня.\n",
      "True answer: {'5', '3'}\n",
      "Predicted answer: {'5', '2'}\n",
      "Task T7014\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная проверяемая гласная корня.\n",
      "True answer: {'1', '5'}\n",
      "Predicted answer: {'1', '2'}\n",
      "Task T6900\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня.\n",
      "True answer: {'3', '5', '2'}\n",
      "Predicted answer: {'3', '2'}\n",
      "Task T7018\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная проверяемая гласная корня.\n",
      "True answer: {'4', '2'}\n",
      "Predicted answer: {'1', '2'}\n",
      "Task T3670\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня.\n",
      "True answer: {'1', '5', '2'}\n",
      "Predicted answer: {'1', '2'}\n",
      "Task T6901\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная непроверяемая гласная корня.\n",
      "True answer: {'1', '4'}\n",
      "Predicted answer: {'5', '4'}\n",
      "Task T7015\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная проверяемая гласная корня.\n",
      "True answer: {'1', '5', '3'}\n",
      "Predicted answer: {'1', '5'}\n",
      "Task T7003\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня.\n",
      "True answer: {'4', '3'}\n",
      "Predicted answer: {'1', '3'}\n",
      "Task T6902\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня.\n",
      "True answer: {'5', '2'}\n",
      "Predicted answer: {'1', '2'}\n",
      "Task T7738\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная непроверяемая гласная корня.\n",
      "True answer: {'4', '3'}\n",
      "Predicted answer: {'5', '2'}\n",
      "Task T8443\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная проверяемая гласная корня.\n",
      "True answer: {'5', '4', '3'}\n",
      "Predicted answer: {'5', '3'}\n",
      "Task T5363\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня.\n",
      "True answer: {'3', '5', '2'}\n",
      "Predicted answer: {'1', '2'}\n",
      "Task T6762\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня.\n",
      "True answer: {'5', '2'}\n",
      "Predicted answer: {'3', '2'}\n",
      "Task T7630\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная непроверяемая гласная корня.\n",
      "True answer: {'1', '4'}\n",
      "Predicted answer: {'1', '3'}\n",
      "Task T1475\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная непроверяемая гласная корня.\n",
      "True answer: {'5', '2'}\n",
      "Predicted answer: {'3', '2'}\n",
      "Task T7666\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня.\n",
      "True answer: {'4', '2'}\n",
      "Predicted answer: {'1', '3'}\n",
      "Task T735\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня. Запишите номера ответов.\n",
      "True answer: {'4', '3'}\n",
      "Predicted answer: {'3', '2'}\n",
      "Task T4928\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня.\n",
      "True answer: {'5', '2'}\n",
      "Predicted answer: {'3', '2'}\n",
      "Task T6954\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная проверяемая гласная корня.\n",
      "True answer: {'3', '2'}\n",
      "Predicted answer: {'1', '2'}\n",
      "Task T6903\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня.\n",
      "True answer: {'5', '3'}\n",
      "Predicted answer: {'1', '3'}\n",
      "Task T1950\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная проверяемая гласная корня.\n",
      "True answer: {'1', '3'}\n",
      "Predicted answer: {'1', '2'}\n",
      "Task T6908\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня.\n",
      "True answer: {'5', '2'}\n",
      "Predicted answer: {'5', '4'}\n",
      "Task T6898\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня.\n",
      "True answer: {'4', '3'}\n",
      "Predicted answer: {'1', '4'}\n",
      "Task T6904\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная непроверяемая гласная корня.\n",
      "True answer: {'4', '2'}\n",
      "Predicted answer: {'1', '4'}\n",
      "Task T5390\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня.\n",
      "True answer: {'1', '5', '4'}\n",
      "Predicted answer: {'4', '3'}\n",
      "Task T3643\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня.\n",
      "True answer: {'4', '3'}\n",
      "Predicted answer: {'1', '2'}\n",
      "Task T7010\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная непроверяемая гласная корня.\n",
      "True answer: {'4', '2'}\n",
      "Predicted answer: {'1', '4'}\n",
      "Task T7007\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня.\n",
      "True answer: {'5', '2'}\n",
      "Predicted answer: {'1', '3'}\n",
      "Task T7011\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная проверяемая гласная корня.\n",
      "True answer: {'1', '5', '4'}\n",
      "Predicted answer: {'1', '3'}\n",
      "Task T6905\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная непроверяемая гласная корня.\n",
      "True answer: {'1', '5', '4'}\n",
      "Predicted answer: {'1', '5'}\n",
      "Task T6899\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня.\n",
      "True answer: {'1', '4'}\n",
      "Predicted answer: {'1', '3'}\n",
      "Task T6909\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная проверяемая гласная корня.\n",
      "True answer: {'1', '4', '3'}\n",
      "Predicted answer: {'1', '5'}\n"
     ]
    }
   ],
   "source": [
    "paths_to_tasks = os.listdir(\"/Users/edgy/Downloads/task_9/\")\n",
    "paths_to_tasks = [t for t in paths_to_tasks if t.startswith(\"T\")]\n",
    "scores_alt = {\"hard\": [], \"soft\": []}\n",
    "scores_ver = {\"hard\": [], \"soft\": []}\n",
    "scores_unver = {\"hard\": [], \"soft\": []}\n",
    "for path_t in paths_to_tasks:\n",
    "    with open(f\"/Users/edgy/Downloads/task_9/{path_t}\", \"r\") as f:\n",
    "        js = json.load(f)\n",
    "    if \"correct\" in js['tasks'][0]['solution']:\n",
    "        true_ans = set(js['tasks'][0]['solution']['correct'])\n",
    "    else: \n",
    "        true_ans = set(js['tasks'][0]['solution']['correct_variants'][0])\n",
    "    answer = set(solver_9(js['tasks'][0]))\n",
    "    soft_score = len(answer.intersection(true_ans)) / len(answer.union(true_ans))\n",
    "    hard_score = answer == true_ans\n",
    "    if \"череду\" in js['tasks'][0][\"text\"]:\n",
    "        scores_alt[\"soft\"].append(soft_score)\n",
    "        scores_alt[\"hard\"].append(hard_score)\n",
    "    if \"непровер\" in js['tasks'][0][\"text\"]:\n",
    "        scores_unver[\"soft\"].append(soft_score)\n",
    "        scores_unver[\"hard\"].append(hard_score)\n",
    "    else:\n",
    "        scores_ver[\"soft\"].append(soft_score)\n",
    "        scores_ver[\"hard\"].append(hard_score)\n",
    "    if not hard_score:\n",
    "        print(f\"Task {path_t.split('.')[0]}\")\n",
    "        print(js[\"tasks\"][0][\"text\"])\n",
    "        print(f\"True answer: {true_ans}\")\n",
    "        print(f\"Predicted answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чередующаяся:  0.46527777777777773 0.20833333333333334\n",
      "Проверяемая:  0.44819819819819817 0.16216216216216217\n",
      "Непроверяемая:  0.6041666666666666 0.4375\n",
      "Total:  0.4859307359307359 0.23376623376623376\n"
     ]
    }
   ],
   "source": [
    "print(\"Чередующаяся: \", np.mean(scores_alt[\"soft\"]), np.mean(scores_alt[\"hard\"]))\n",
    "print(\"Проверяемая: \", np.mean(scores_ver[\"soft\"]), np.mean(scores_ver[\"hard\"]))\n",
    "print(\"Непроверяемая: \", np.mean(scores_unver[\"soft\"]), np.mean(scores_unver[\"hard\"]))\n",
    "print(\"Total: \", np.mean(scores_unver[\"soft\"]+scores_alt[\"soft\"]+scores_ver[\"soft\"]),\n",
    "      np.mean(scores_unver[\"hard\"]+scores_alt[\"hard\"]+scores_ver[\"hard\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_exists(w):\n",
    "    analysis = morph.parse(w)\n",
    "    if (analysis[0].methods_stack[0][0].__class__.__name__ == \"DictionaryAnalyzer\") and\\\n",
    "       (analysis[0].methods_stack[0][1] == w):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def solver_9(task, testing=False):\n",
    "    def is_unverifiable(w):\n",
    "        for w2 in slovarnie_slova.word:\n",
    "            if re.match(re.sub(r\"[\\.]+\", \".\", w), w2):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def is_stressed(w, pos):\n",
    "        if len(w) == pos:\n",
    "            w = w[:pos] + w[pos].upper()\n",
    "        else:\n",
    "            w = w[:pos] + w[pos].upper() + w[pos+1:]\n",
    "        return w in stress_dict.word.values\n",
    "\n",
    "    def possible_variants(w):\n",
    "        amount = 0\n",
    "        for candidate in \"аоеиы\":\n",
    "            w_n = re.sub(r\"[\\.]+\", candidate, w)\n",
    "            if word_exists(w_n):\n",
    "                amount += 1\n",
    "        if amount == 0:\n",
    "            amount = 1\n",
    "        return amount\n",
    "\n",
    "    def is_alternant(w):\n",
    "        #зависящие от конечной согласной корня\n",
    "        patterns_1 = [\n",
    "            (r\"[а-я]*р[\\.]+(ст|щ)[а-я]*\", \"а\"),\n",
    "            (r\"[а-я]*р[\\.]+с[а-су-я]*\", \"о\"),\n",
    "            (r\"[а-я]*л[\\.]+г[а-я]*\", \"а\"),\n",
    "            (r\"[а-я]*л[\\.]+ж[а-я]*\", \"о\"),\n",
    "            (r\"[а-я]*ск[\\.]+к[а-я]*\", \"а\"),\n",
    "            (r\"[а-я]*ск[\\.]+ч[а-я]*\", \"о\"),\n",
    "        ]\n",
    "        #зависящие от суффикса \"а\" после корня\n",
    "        patterns_2 = [\n",
    "            (r\"[а-я]*(б|д|м|п|т)[\\.]+ра[а-я]*\", \"и\"),\n",
    "            (r\"[а-я]*бл[\\.]+ста[а-я]*\", \"и\"),\n",
    "            (r\"[а-я]*ж[\\.]+га[а-я]*\", \"и\"),\n",
    "            (r\"[а-я]*ст[\\.]+ла[а-я]*\", \"и\"),\n",
    "            (r\"[а-я]*ч[\\.]+та[а-я]*\", \"и\"),\n",
    "            (r\"[а-я]*к[\\.]+са[а-я]*\", \"а\"),\n",
    "            (r\"[а-я]*(б|д|м|п|т)[\\.]+р[б-я]*\", \"е\"),\n",
    "            (r\"[а-я]*бл[\\.]+ст[б-я]*\", \"е\"),\n",
    "            (r\"[а-я]*ж[\\.]+г[б-я]*\", \"е\"),\n",
    "            (r\"[а-я]*ст[\\.]+л[б-я]*\", \"е\"),\n",
    "            (r\"[а-я]*ч[\\.]+т[б-я]*\", \"е\"),\n",
    "            (r\"[а-я]*к[\\.]+с[б-я]*\", \"о\"),\n",
    "        ]\n",
    "        #зависящие от ударения (плов-плав хз почему тут, всегда пишется \"а\" кроме исключений)\n",
    "        patterns_3a = [\n",
    "            (r\"[а-я]*з[\\.]+р[а-я]*\", \"оа\"),\n",
    "            (r\"[а-я]*г[\\.]+р[а-я]*\", \"ао\"),\n",
    "            (r\"[а-я]*тв[\\.]+р[а-нп-я]+\", \"ао\"),\n",
    "        ]\n",
    "        patterns_3b = [\n",
    "            (r\"[а-я]*пл[\\.]+в[а-я]*\", \"оа\"),\n",
    "        ]\n",
    "        #зависящие от лексического значения\n",
    "        patterns_4 = [\n",
    "            (r\"[а-я]*м[\\.]+к[а-я]*\", \"оа\"),\n",
    "            (r\"[а-я]*р[\\.]+вн[а-я]*\", \"оа\"),\n",
    "        ]\n",
    "\n",
    "        exceptions = [\n",
    "            r\"росток\", r\"ростов\", r\"ростислав\", r\"ростовщик\",\n",
    "            r\"отрасль\", r\"скачок\", r\"скачу\", r\"сочетать\", r\"сочетание\",\n",
    "            r\"чета\", r\"зоревать\", r\"зорянка\", r\"пловец\", r\"пловчиха\",\n",
    "            r\"плывун[ы]{0,1}\", r\"уровень\", r\"ровесник\", r\"равнина\", r\"равняйсь\", \n",
    "            r\"равнение \",\n",
    "        ]\n",
    "        w = w.lower()\n",
    "        pos_space = re.search(r\"\\.\", w).span()[0]\n",
    "        for p in patterns_1:\n",
    "            if re.match(p[0], w):\n",
    "                for p_i in p[1]:\n",
    "                    filled_w = re.sub(r\"[\\.]+\", p_i, w)\n",
    "                    if word_exists(filled_w):\n",
    "                        stressed = is_stressed(filled_w, pos_space)\n",
    "                        return True, 1, filled_w, pos_space, stressed\n",
    "        for p in patterns_2:\n",
    "            if re.match(p[0], w):\n",
    "                for p_i in p[1]:\n",
    "                    filled_w = re.sub(r\"[\\.]+\", p_i, w)\n",
    "                    if word_exists(filled_w):\n",
    "                        stressed = is_stressed(filled_w, pos_space)\n",
    "                        return True, 2, filled_w, pos_space, stressed\n",
    "        for p in patterns_4:\n",
    "            if re.match(p[0], w):\n",
    "                for p_i in p[1]:\n",
    "                    filled_w = re.sub(r\"[\\.]+\", p_i, w)\n",
    "                    if word_exists(filled_w):\n",
    "                        stressed = is_stressed(filled_w, pos_space)\n",
    "                        return True, 4, filled_w, pos_space, stressed\n",
    "        for p in patterns_3a:\n",
    "            if re.match(p[0], w):\n",
    "                for q, p_i in enumerate(p[1]):\n",
    "                    filled_w = re.sub(r\"[\\.]+\", p_i, w)\n",
    "                    if word_exists(filled_w):\n",
    "                        stress_ind = is_stressed(filled_w, pos_space)\n",
    "                        if (stress_ind) and (q == 0):\n",
    "                            return True, 3, filled_w, pos_space, True\n",
    "                        if (q == 1) and (not stress_ind):\n",
    "                            return True, 3, filled_w, pos_space, False\n",
    "        for p in patterns_3b:\n",
    "            if re.match(p[0], w):\n",
    "                for p_i in p[1]:\n",
    "                    filled_w = re.sub(r\"[\\.]+\", p_i, w)\n",
    "                    if word_exists(filled_w):\n",
    "                        stressed = is_stressed(filled_w, pos_space)\n",
    "                        return True, 3, filled_w, pos_space, stressed\n",
    "        return False, None, None, pos_space, None\n",
    "\n",
    "    words = np.array([re.split(r\", \", t[\"text\"]) for t in task[\"question\"][\"choices\"]])\n",
    "    #обрезаем цифры \n",
    "    words = [[re.sub(r\"…\", \"..\", re.sub(r\"[0-9]+\\)\", \"\", t2)).strip() for t2 in t1] for t1 in words]\n",
    "    exact_types = np.zeros((len(words), len(words[0]))).astype(int)-1\n",
    "    for i in range(exact_types.shape[0]):\n",
    "        for j in range(exact_types.shape[1]):\n",
    "            if words[i][j] in exact_labels[\"alt\"]:\n",
    "                exact_types[i, j] = 0\n",
    "            elif words[i][j] in exact_labels[\"unver\"]:\n",
    "                exact_types[i, j] = 1\n",
    "            elif words[i][j] in exact_labels[\"ver\"]:\n",
    "                exact_types[i, j] = 2\n",
    "    words = [[re.sub(r\"\\([а-я ]+\\)\", \"\", t2).strip() for t2 in t1] for t1 in words]\n",
    "\n",
    "    #определяем какой тип нужно искать\n",
    "    if \"чередующ\" in task[\"text\"]:\n",
    "        task_type = 0\n",
    "    elif \"непровер\" in task[\"text\"]:\n",
    "        task_type = 1\n",
    "    else:\n",
    "        task_type = 2\n",
    "        \n",
    "    alt_labels = [[is_alternant(t2) for t2 in t1] for t1 in words]\n",
    "    unver_labels = [[is_unverifiable(t2) for t2 in t1] for t1 in words]\n",
    "    possible_ways = [[possible_variants(t2) for t2 in t1] for t1 in words]\n",
    "    scores = np.zeros((len(words), len(words[0]), 3))\n",
    "    for i in range(scores.shape[0]):\n",
    "        for j in range(scores.shape[1]):\n",
    "            if exact_types[i, j] >= 0:\n",
    "                if exact_types[i, j] != task_type:\n",
    "                    scores[i, :, task_type] = -100\n",
    "                    break\n",
    "                scores[i, j, exact_types[i, j]] = 1\n",
    "            else:\n",
    "                scores[i, j, 0] = 0\n",
    "                scores[i, j, 1] = unver_labels[i][j] * 0.9\n",
    "                if alt_labels[i][j][0]:\n",
    "                    scores[i, j, 0] = alt_labels[i][j][0] * 0.9\n",
    "                scores[i, j, 2] = 0.9 - 0.5 * (scores[i, j, 0] + scores[i, j, 1])\n",
    "                \n",
    "    if testing: print(scores)\n",
    "    agg_scores = scores.mean(axis=1)\n",
    "    if testing: print(agg_scores)\n",
    "    agg_scores = agg_scores[:, task_type]\n",
    "    if testing: print(agg_scores)\n",
    "    max_score = agg_scores.max()\n",
    "    second_value = agg_scores[agg_scores.argsort()[-2]]\n",
    "    answer_numbers = np.arange(len(agg_scores))[agg_scores==max_score]\n",
    "    if ((len(answer_numbers) < 2) and (second_value > 0)) or ((len(answer_numbers) == 2) and (second_value > 2.2)):\n",
    "        answer_numbers = np.concatenate([answer_numbers,\n",
    "                                         np.arange(len(agg_scores))[agg_scores==second_value]])\n",
    "        if second_value > 2.2:\n",
    "            answer_numbers = answer_numbers[:3]\n",
    "        else:\n",
    "            answer_numbers = answer_numbers[:2]\n",
    "    answer_numbers += 1\n",
    "    answer_numbers = [str(t) for t in answer_numbers]\n",
    "    return answer_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task T7009\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная проверяемая гласная корня.\n",
      "True answer: {'5', '4'}\n",
      "Predicted answer: {'4', '3'}\n",
      "Task T6903\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня.\n",
      "True answer: {'5', '3'}\n",
      "Predicted answer: {'1', '3'}\n",
      "Task T6908\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня.\n",
      "True answer: {'5', '2'}\n",
      "Predicted answer: {'5', '4'}\n",
      "Task T6899\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная чередующаяся гласная корня.\n",
      "True answer: {'1', '4'}\n",
      "Predicted answer: {'1', '3'}\n",
      "Task T6909\n",
      "Укажите варианты ответов, в которых во всех словах одного ряда пропущена безударная проверяемая гласная корня.\n",
      "True answer: {'1', '4', '3'}\n",
      "Predicted answer: {'1', '3'}\n"
     ]
    }
   ],
   "source": [
    "paths_to_tasks = os.listdir(\"/Users/edgy/Downloads/task_9/\")\n",
    "paths_to_tasks = [t for t in paths_to_tasks if t.startswith(\"T\")]\n",
    "scores_alt = {\"hard\": [], \"soft\": []}\n",
    "scores_ver = {\"hard\": [], \"soft\": []}\n",
    "scores_unver = {\"hard\": [], \"soft\": []}\n",
    "for path_t in paths_to_tasks:\n",
    "    with open(f\"/Users/edgy/Downloads/task_9/{path_t}\", \"r\") as f:\n",
    "        js = json.load(f)\n",
    "    if \"correct\" in js['tasks'][0]['solution']:\n",
    "        true_ans = set(js['tasks'][0]['solution']['correct'])\n",
    "    else: \n",
    "        true_ans = set(js['tasks'][0]['solution']['correct_variants'][0])\n",
    "    answer = set(solver_9(js['tasks'][0]))\n",
    "    soft_score = len(answer.intersection(true_ans)) / len(answer.union(true_ans))\n",
    "    hard_score = answer == true_ans\n",
    "    if \"череду\" in js['tasks'][0][\"text\"]:\n",
    "        scores_alt[\"soft\"].append(soft_score)\n",
    "        scores_alt[\"hard\"].append(hard_score)\n",
    "    if \"непровер\" in js['tasks'][0][\"text\"]:\n",
    "        scores_unver[\"soft\"].append(soft_score)\n",
    "        scores_unver[\"hard\"].append(hard_score)\n",
    "    else:\n",
    "        scores_ver[\"soft\"].append(soft_score)\n",
    "        scores_ver[\"hard\"].append(hard_score)\n",
    "    if not hard_score:\n",
    "        print(f\"Task {path_t.split('.')[0]}\")\n",
    "        print(js[\"tasks\"][0][\"text\"])\n",
    "        print(f\"True answer: {true_ans}\")\n",
    "        print(f\"Predicted answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чередующаяся:  0.9166666666666666 0.875\n",
      "Проверяемая:  0.918918918918919 0.8648648648648649\n",
      "Непроверяемая:  1.0 1.0\n",
      "Total:  0.935064935064935 0.8961038961038961\n"
     ]
    }
   ],
   "source": [
    "print(\"Чередующаяся: \", np.mean(scores_alt[\"soft\"]), np.mean(scores_alt[\"hard\"]))\n",
    "print(\"Проверяемая: \", np.mean(scores_ver[\"soft\"]), np.mean(scores_ver[\"hard\"]))\n",
    "print(\"Непроверяемая: \", np.mean(scores_unver[\"soft\"]), np.mean(scores_unver[\"hard\"]))\n",
    "print(\"Total: \", np.mean(scores_unver[\"soft\"]+scores_alt[\"soft\"]+scores_ver[\"soft\"]),\n",
    "      np.mean(scores_unver[\"hard\"]+scores_alt[\"hard\"]+scores_ver[\"hard\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чередующаяся:  0.4416666666666667\n",
      "Проверяемая:  0.4540540540540541\n",
      "Непроверяемая:  0.41250000000000003\n",
      "Total:  0.44155844155844154\n"
     ]
    }
   ],
   "source": [
    "paths_to_tasks = os.listdir(\"/Users/edgy/Downloads/task_9/\")\n",
    "paths_to_tasks = [t for t in paths_to_tasks if t.startswith(\"T\")]\n",
    "scores_alt = []\n",
    "scores_ver = []\n",
    "scores_unver = []\n",
    "for path_t in paths_to_tasks:\n",
    "    with open(f\"/Users/edgy/Downloads/task_9/{path_t}\", \"r\") as f:\n",
    "        js = json.load(f)\n",
    "    if \"correct\" in js['tasks'][0]['solution']:\n",
    "        true_ans = set(js['tasks'][0]['solution']['correct'])\n",
    "    else: \n",
    "        true_ans = set(js['tasks'][0]['solution']['correct_variants'][0])\n",
    "    answer = {\"1\", \"2\", \"3\", \"4\", \"5\"}\n",
    "    last_score = len(answer.intersection(true_ans)) / len(answer.union(true_ans))\n",
    "    if \"череду\" in js['tasks'][0][\"text\"]:\n",
    "        scores_alt.append(last_score)\n",
    "    if \"непровер\" in js['tasks'][0][\"text\"]:\n",
    "        scores_unver.append(last_score)\n",
    "    else:\n",
    "        scores_ver.append(last_score)\n",
    "        \n",
    "print(\"Чередующаяся: \", np.mean(scores_alt))\n",
    "print(\"Проверяемая: \", np.mean(scores_ver))\n",
    "print(\"Непроверяемая: \", np.mean(scores_unver))\n",
    "print(\"Total: \", np.mean(scores_unver+scores_alt+scores_ver))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import codecs\n",
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "import tokenization\n",
    "\n",
    "# bert_folder = 'multi_cased_L-12_H-768_A-12'\n",
    "rubert_folder = \"/Users/edgy/Downloads/rubert_cased_L-12_H-768_A-12_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1009 22:09:41.423934 140735486686080 deprecation_wrapper.py:119] From /Users/edgy/projects/ai-journey-2019/notebooks/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1009 22:09:41.835791 140735486686080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1009 22:09:41.876387 140735486686080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1009 22:09:41.932894 140735486686080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1009 22:09:41.933692 140735486686080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1009 22:09:41.941823 140735486686080 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1009 22:09:41.979249 140735486686080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# bert_tokenizer = tokenization.FullTokenizer(vocab_file=bert_folder+'/vocab.txt',\n",
    "#                                             do_lower_case=False)\n",
    "# bert = load_trained_model_from_checkpoint(bert_folder+'/bert_config.json',\n",
    "#                                           bert_folder+'/bert_model.ckpt',\n",
    "#                                           training=True)\n",
    "rubert_tokenizer = tokenization.FullTokenizer(vocab_file=rubert_folder+'/vocab.txt',\n",
    "                                              do_lower_case=False)\n",
    "rubert = load_trained_model_from_checkpoint(rubert_folder+'/bert_config.json',\n",
    "                                            rubert_folder+'/bert_model.ckpt',\n",
    "                                            training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solver_17(task, threshold=0.5, testing=False):\n",
    "    \n",
    "    max_length = 512\n",
    "    \n",
    "    text = task[\"text\"]\n",
    "    text = re.sub(r\"\\(\\d\\)\", \"[MASK]\", text)\n",
    "    if testing:\n",
    "        print(text)\n",
    "    text = text.replace(\"[ ]*\\[MASK\\][ ]*\",\"[MASK]\")\n",
    "    text = text.split(\"[MASK]\")\n",
    "    \n",
    "    tokens = [\"[CLS]\"]\n",
    "    for i in range(len(text)):\n",
    "        if i == 0:\n",
    "            tokens = tokens + tokenizer.tokenize(text[i]) \n",
    "        else:\n",
    "            tokens = tokens + ['[MASK]'] + tokenizer.tokenize(text[i]) \n",
    "    tokens = tokens + ['[SEP]'] \n",
    "    token_input = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    token_input = np.array(token_input + [0] * (512 - len(token_input)))\n",
    "    \n",
    "    mask_input = np.zeros(max_length)\n",
    "    mask_input[token_input == 103] = 1\n",
    "    \n",
    "    seg_input = np.zeros(max_length)\n",
    "    predicts = model.predict([token_input.reshape(1, -1), seg_input.reshape(1, -1), mask_input.reshape(1, -1)])[0]\n",
    "    comma_likelihoods = predicts[0, :, 117][mask_input.astype(bool)]\n",
    "    dot_likelihoods = predicts[0, :, 119][mask_input.astype(bool)]\n",
    "    and_likelihoods = predicts[0, :, 549][mask_input.astype(bool)]\n",
    "    or_likelihoods = predicts[0, :, 10880][mask_input.astype(bool)]\n",
    "    complex_likelihoods = [t1 + t2 for t1, t2 in zip(comma_likelihoods, and_likelihoods)]\n",
    "    if testing: print(f\"',': {comma_likelihoods}, '.': {dot_likelihoods}, 'и': {and_likelihoods}, 'или': {or_likelihoods}\")\n",
    "    return [str(i+1) for i, t in enumerate(complex_likelihoods) if t >= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_tasks = os.listdir(\"/Users/edgy/Downloads/task_17/\")\n",
    "paths_to_tasks = [t for t in paths_to_tasks if t.startswith(\"T\")]\n",
    "scores = []\n",
    "\n",
    "for path_t in tqdm_notebook(paths_to_tasks[:]):\n",
    "    with open(f\"/Users/edgy/Downloads/task_17/{path_t}\", \"r\") as f:\n",
    "        js = json.load(f)\n",
    "    if \"correct\" in js['tasks'][0]['solution']:\n",
    "        true_ans = set(js['tasks'][0]['solution']['correct'])\n",
    "    else: \n",
    "        true_ans = set(js['tasks'][0]['solution']['correct_variants'][0])\n",
    "    answer = set(solver_17(js[\"tasks\"][0], testing=True))\n",
    "    print(\"true: \", true_ans)\n",
    "    score = len(answer.intersection(true_ans)) / len(answer.union(true_ans))\n",
    "    scores.append(score)\n",
    "\n",
    "print(\"Score: \", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_tasks = os.listdir(\"/Users/edgy/Downloads/task_17/\")\n",
    "paths_to_tasks = [t for t in paths_to_tasks if t.startswith(\"T\")]\n",
    "scores_t = []\n",
    "\n",
    "for path_t in tqdm_notebook(paths_to_tasks):\n",
    "    with open(f\"/Users/edgy/Downloads/task_17/{path_t}\", \"r\") as f:\n",
    "        js = json.load(f)\n",
    "    if \"correct\" in js['tasks'][0]['solution']:\n",
    "        true_ans = set(js['tasks'][0]['solution']['correct'])\n",
    "    else: \n",
    "        true_ans = set(js['tasks'][0]['solution']['correct_variants'][0])\n",
    "    answer = set([t[\"id\"] for t in js[\"tasks\"][0][\"question\"][\"choices\"]])\n",
    "    score = len(answer.intersection(true_ans)) / len(answer.union(true_ans))\n",
    "    scores_t.append(score)\n",
    "\n",
    "print(\"Score: \", np.mean(scores_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp(task, model=rubert, tokenizer=rubert_tokenizer):\n",
    "    \n",
    "    max_length = 512\n",
    "    \n",
    "    text = task[\"text\"]\n",
    "#     for l in \"ЙЦУКЕНГШЩЗХЪФЫВАПРОЛДЖЭЁЯЧСМИТЬБЮ\":\n",
    "#         text = re.sub(fr\"\\n{l}\", \" \"+l.lower(), text)\n",
    "    text = re.sub(r\"\\(\\d\\)\", \"[MASK]\", text)\n",
    "    text = text.replace(\"[ ]*\\[MASK\\][ ]*\",\"[MASK]\")\n",
    "    text = text.split(\"[MASK]\")\n",
    "    \n",
    "    tokens = [\"[CLS]\"]\n",
    "    for i in range(len(text)):\n",
    "        if i == 0:\n",
    "            tokens = tokens + tokenizer.tokenize(text[i]) \n",
    "        else:\n",
    "            tokens = tokens + ['[MASK]'] + tokenizer.tokenize(text[i]) \n",
    "    tokens = tokens + ['[SEP]'] \n",
    "    token_input = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    token_input = np.array(token_input + [0] * (512 - len(token_input)))\n",
    "    \n",
    "    mask_input = np.zeros(max_length)\n",
    "    mask_token_id = tokenizer.convert_tokens_to_ids([\"[MASK]\"])[0]\n",
    "    mask_input[token_input == mask_token_id] = 1\n",
    "    \n",
    "    seg_input = np.zeros(max_length)\n",
    "    predicts = model.predict([token_input.reshape(1, -1), seg_input.reshape(1, -1), mask_input.reshape(1, -1)])[0]\n",
    "    comma_id = tokenizer.convert_tokens_to_ids([\",\"])[0]\n",
    "    dot_id = tokenizer.convert_tokens_to_ids([\".\"])[0]\n",
    "    or_id = tokenizer.convert_tokens_to_ids([\"или\"])[0]\n",
    "    and_id = tokenizer.convert_tokens_to_ids([\"и\"])[0]\n",
    "    dotcom_id = tokenizer.convert_tokens_to_ids([\";\"])[0]\n",
    "    or2_id = tokenizer.convert_tokens_to_ids([\"либо\"])[0]\n",
    "    with_id = tokenizer.convert_tokens_to_ids([\"с\"])[0]\n",
    "    tire_id = tokenizer.convert_tokens_to_ids([\"-\"])[0]\n",
    "    da_id = tokenizer.convert_tokens_to_ids([\"да\"])[0]\n",
    "    comma_likelihoods = predicts[0, :, comma_id][mask_input.astype(bool)]\n",
    "    dot_likelihoods = predicts[0, :, dot_id][mask_input.astype(bool)]\n",
    "    and_likelihoods = predicts[0, :, and_id][mask_input.astype(bool)]\n",
    "    or_likelihoods = predicts[0, :, or_id][mask_input.astype(bool)]\n",
    "    dotcom_likelihoods = predicts[0, :, dotcom_id][mask_input.astype(bool)]\n",
    "    or2_likelihoods = predicts[0, :, or2_id][mask_input.astype(bool)]\n",
    "    with_likelihoods = predicts[0, :, with_id][mask_input.astype(bool)]\n",
    "    tire_likelihoods = predicts[0, :, tire_id][mask_input.astype(bool)]\n",
    "    da_likelihoods = predicts[0, :, da_id][mask_input.astype(bool)]\n",
    "    return comma_likelihoods, dot_likelihoods, and_likelihoods, or_likelihoods,\\\n",
    "           dotcom_likelihoods, or2_likelihoods, with_likelihoods, tire_likelihoods,\\\n",
    "           da_likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a90a1751eb44a739cfdc2a9bf75077e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=62), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7391c5188def4349a839bc85d4c9b967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd21f72de55475f9758c25c4a8281de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=62), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25550cc5553645b68405d9c475125460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=62), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame(columns=[\"task#\", \"task_id\", \"comma\", \"dot\", \"and\", \"or\", \"dotcom\",\n",
    "                            \"or2\", \"with\", \"tire\", \"da\", \"true\", \"is_ru\"])\n",
    "\n",
    "for task_number in [17, 18, 19, 20]:\n",
    "    paths_to_tasks = os.listdir(f\"/Users/edgy/Downloads/task_{task_number}/\")\n",
    "    paths_to_tasks = [t for t in paths_to_tasks if t.startswith(\"T\")]\n",
    "    for path_t in tqdm_notebook(paths_to_tasks):\n",
    "        with open(f\"/Users/edgy/Downloads/task_{task_number}/{path_t}\", \"r\") as f:\n",
    "            js = json.load(f)\n",
    "        if \"correct\" in js['tasks'][0]['solution']:\n",
    "            true_ans = set(js['tasks'][0]['solution']['correct'])\n",
    "        else: \n",
    "            true_ans = set(js['tasks'][0]['solution']['correct_variants'][0])\n",
    "        model = rubert\n",
    "        tokenizer = rubert_tokenizer\n",
    "        comma_likelihoods, dot_likelihoods, and_likelihoods, or_likelihoods, dotcom_likelihoods, or2_likelihoods, with_likelihoods, tire_likelihoods, da_likelihoods = tmp(js[\"tasks\"][0], model=model, tokenizer=tokenizer)\n",
    "        for i, _ in enumerate(comma_likelihoods):\n",
    "            true = 0\n",
    "            if str(i + 1) in true_ans:\n",
    "                true = 1\n",
    "            model_name = \"rubert\"\n",
    "            df2.loc[len(df2)] = [task_number,\n",
    "                                   path_t,\n",
    "                                   comma_likelihoods[i],\n",
    "                                   dot_likelihoods[i],\n",
    "                                   and_likelihoods[i],\n",
    "                                   or_likelihoods[i],\n",
    "                                   dotcom_likelihoods[i],\n",
    "                                   or2_likelihoods[i],\n",
    "                                   with_likelihoods[i],\n",
    "                                   tire_likelihoods[i],\n",
    "                                   da_likelihoods[i],\n",
    "                                   true,\n",
    "                                   model_name,\n",
    "                                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8913043478260869\n",
      "Baseline: 0.577639751552795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_t = df2[(df2[\"task#\"]==17) & (df2[\"is_ru\"]==\"rubert\")]\n",
    "true = df_t[\"true\"].values.astype(int)\n",
    "comma_ru = df_t[\"comma\"].values\n",
    "dot_ru = df_t[\"dot\"].values\n",
    "an_ru = df_t[\"and\"].values\n",
    "o_ru = df_t[\"or\"].values\n",
    "preds = (comma_ru + an_ru + dot_ru > 0.65).astype(int)\n",
    "print(f\"Accuracy: {accuracy_score(true, preds)}\")\n",
    "print(f\"Baseline: {sum(true) / len(true)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8913043478260869\n",
      "Baseline: 0.577639751552795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_t = df2[(df2[\"task#\"]==17) & (df2[\"is_ru\"]==\"rubert\")]\n",
    "true = df_t[\"true\"].values.astype(int)\n",
    "comma_ru = df_t[\"comma\"].values\n",
    "dot_ru = df_t[\"dot\"].values\n",
    "an_ru = df_t[\"and\"].values\n",
    "o_ru = df_t[\"or\"].values\n",
    "dotcom_ru = df_t[\"dotcom\"].values\n",
    "or2_ru = df_t[\"or2\"].values\n",
    "with_ru = df_t[\"with\"].values\n",
    "tire_ru = df_t[\"tire\"].values\n",
    "da_ru = df_t[\"da\"].values\n",
    "preds = (comma_ru + an_ru + dot_ru > 0.65).astype(int)\n",
    "print(f\"Accuracy: {accuracy_score(true, preds)}\")\n",
    "print(f\"Baseline: {sum(true) / len(true)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.743859649122807\n",
      "Baseline: 0.5578947368421052\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_t = df2[(df2[\"task#\"]==18) & (df2[\"is_ru\"]==\"rubert\")]\n",
    "true = df_t[\"true\"].values.astype(int)\n",
    "comma = df_t[\"comma\"].values\n",
    "dot = df_t[\"dot\"].values\n",
    "an = df_t[\"and\"].values\n",
    "o = df_t[\"or\"].values\n",
    "dotcom_ru = df_t[\"dotcom\"].values\n",
    "or2_ru = df_t[\"or2\"].values\n",
    "with_ru = df_t[\"with\"].values\n",
    "tire_ru = df_t[\"tire\"].values\n",
    "da_ru = df_t[\"da\"].values\n",
    "preds = (comma + dot + an > 0.35).astype(int)\n",
    "print(f\"Accuracy: {accuracy_score(true, preds)}\")\n",
    "print(f\"Baseline: {sum(true) / len(true)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7543859649122807\n",
      "Baseline: 0.5578947368421052\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_t = df2[(df2[\"task#\"]==18) & (df2[\"is_ru\"]==\"rubert\")]\n",
    "true = df_t[\"true\"].values.astype(int)\n",
    "comma_ru = df_t[\"comma\"].values\n",
    "dot_ru = df_t[\"dot\"].values\n",
    "an_ru = df_t[\"and\"].values\n",
    "o_ru = df_t[\"or\"].values\n",
    "dotcom_ru = df_t[\"dotcom\"].values\n",
    "or2_ru = df_t[\"or2\"].values\n",
    "with_ru = df_t[\"with\"].values\n",
    "tire_ru = df_t[\"tire\"].values\n",
    "da_ru = df_t[\"da\"].values\n",
    "preds = (comma_ru + dot_ru + an_ru + with_ru + dotcom_ru > 0.3).astype(int)\n",
    "print(f\"Accuracy: {accuracy_score(true, preds)}\")\n",
    "print(f\"Baseline: {sum(true) / len(true)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8681318681318682\n",
      "Baseline: 0.5238095238095238\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_t = df2[(df2[\"task#\"]==19) & (df2[\"is_ru\"]==\"rubert\")]\n",
    "true = df_t[\"true\"].values.astype(int)\n",
    "comma_ru = df_t[\"comma\"].values\n",
    "dot_ru = df_t[\"dot\"].values\n",
    "an_ru = df_t[\"and\"].values\n",
    "o_ru = df_t[\"or\"].values\n",
    "dotcom_ru = df_t[\"dotcom\"].values\n",
    "or2_ru = df_t[\"or2\"].values\n",
    "with_ru = df_t[\"with\"].values\n",
    "tire_ru = df_t[\"tire\"].values\n",
    "da_ru = df_t[\"da\"].values\n",
    "preds = (comma_ru + dot_ru + o_ru > 0.55).astype(int)\n",
    "print(f\"Accuracy: {accuracy_score(true, preds)}\")\n",
    "print(f\"Baseline: {sum(true) / len(true)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8681318681318682\n",
      "Baseline: 0.5238095238095238\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_t = df2[(df2[\"task#\"]==19) & (df2[\"is_ru\"]==\"rubert\")]\n",
    "true = df_t[\"true\"].values.astype(int)\n",
    "comma_ru = df_t[\"comma\"].values\n",
    "dot_ru = df_t[\"dot\"].values\n",
    "an_ru = df_t[\"and\"].values\n",
    "o_ru = df_t[\"or\"].values\n",
    "dotcom_ru = df_t[\"dotcom\"].values\n",
    "or2_ru = df_t[\"or2\"].values\n",
    "with_ru = df_t[\"with\"].values\n",
    "tire_ru = df_t[\"tire\"].values\n",
    "da_ru = df_t[\"da\"].values\n",
    "preds = (comma_ru + dot_ru + o_ru > 0.55).astype(int)\n",
    "print(f\"Accuracy: {accuracy_score(true, preds)}\")\n",
    "print(f\"Baseline: {sum(true) / len(true)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8237179487179487\n",
      "Baseline: 0.7115384615384616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_t = df2[(df2[\"task#\"]==20) & (df2[\"is_ru\"]==\"rubert\")]\n",
    "true = df_t[\"true\"].values.astype(int)\n",
    "comma_ru = df_t[\"comma\"].values\n",
    "dot_ru = df_t[\"dot\"].values\n",
    "an_ru = df_t[\"and\"].values\n",
    "o_ru = df_t[\"or\"].values\n",
    "dotcom_ru = df_t[\"dotcom\"].values\n",
    "or2_ru = df_t[\"or2\"].values\n",
    "with_ru = df_t[\"with\"].values\n",
    "tire_ru = df_t[\"tire\"].values\n",
    "da_ru = df_t[\"da\"].values\n",
    "preds = (comma_ru > 0.7).astype(int)\n",
    "print(f\"Accuracy: {accuracy_score(true, preds)}\")\n",
    "print(f\"Baseline: {sum(true) / len(true)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8237179487179487\n",
      "Baseline: 0.7115384615384616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_t = df2[(df2[\"task#\"]==20) & (df2[\"is_ru\"]==\"rubert\")]\n",
    "true = df_t[\"true\"].values.astype(int)\n",
    "comma_ru = df_t[\"comma\"].values\n",
    "dot_ru = df_t[\"dot\"].values\n",
    "an_ru = df_t[\"and\"].values\n",
    "o_ru = df_t[\"or\"].values\n",
    "dotcom_ru = df_t[\"dotcom\"].values\n",
    "or2_ru = df_t[\"or2\"].values\n",
    "with_ru = df_t[\"with\"].values\n",
    "tire_ru = df_t[\"tire\"].values\n",
    "da_ru = df_t[\"da\"].values\n",
    "preds = (comma_ru > 0.7).astype(int)\n",
    "print(f\"Accuracy: {accuracy_score(true, preds)}\")\n",
    "print(f\"Baseline: {sum(true) / len(true)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_tasks = os.listdir(\"/Users/edgy/Downloads/task_18/\")\n",
    "paths_to_tasks = [t for t in paths_to_tasks if t.startswith(\"T\")]\n",
    "scores = []\n",
    "\n",
    "for path_t in tqdm_notebook(paths_to_tasks):\n",
    "    with open(f\"/Users/edgy/Downloads/task_18/{path_t}\", \"r\") as f:\n",
    "        js = json.load(f)\n",
    "    text = js[\"tasks\"][0][\"text\"]\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    for l in \"ЙЦУКЕНГШЩЗХФЫВАПРОЛДЖЭЁЯЧСМИТЬБЮ\":\n",
    "        if \" \" +l in text:\n",
    "            text = re.sub(\" \" +l, \" \" +l.lower(), text)\n",
    "    js[\"tasks\"][0][\"text\"] = text\n",
    "    if \"correct\" in js['tasks'][0]['solution']:\n",
    "        true_ans = set(js['tasks'][0]['solution']['correct'])\n",
    "    else: \n",
    "        true_ans = set(js['tasks'][0]['solution']['correct_variants'][0])\n",
    "    answer = set(solver_17(js[\"tasks\"][0], True, threshold=0.001))\n",
    "    print(\"true: \", true_ans)\n",
    "    score = len(answer.intersection(true_ans)) / len(answer.union(true_ans))\n",
    "    scores.append(score)\n",
    "\n",
    "print(\"Score: \", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_tasks = os.listdir(\"/Users/edgy/Downloads/task_18/\")\n",
    "paths_to_tasks = [t for t in paths_to_tasks if t.startswith(\"T\")]\n",
    "scores_t = []\n",
    "\n",
    "for path_t in tqdm_notebook(paths_to_tasks):\n",
    "    with open(f\"/Users/edgy/Downloads/task_18/{path_t}\", \"r\") as f:\n",
    "        js = json.load(f)\n",
    "    if \"correct\" in js['tasks'][0]['solution']:\n",
    "        true_ans = set(js['tasks'][0]['solution']['correct'])\n",
    "    else: \n",
    "        true_ans = set(js['tasks'][0]['solution']['correct_variants'][0])\n",
    "    answer = set([t[\"id\"] for t in js[\"tasks\"][0][\"question\"][\"choices\"]])\n",
    "    score = len(answer.intersection(true_ans)) / len(answer.union(true_ans))\n",
    "    scores_t.append(score)\n",
    "\n",
    "print(\"Score: \", np.mean(scores_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_tasks = os.listdir(\"/Users/edgy/Downloads/task_19/\")\n",
    "paths_to_tasks = [t for t in paths_to_tasks if t.startswith(\"T\")]\n",
    "scores = []\n",
    "\n",
    "for path_t in tqdm_notebook(paths_to_tasks):\n",
    "    with open(f\"/Users/edgy/Downloads/task_19/{path_t}\", \"r\") as f:\n",
    "        js = json.load(f)\n",
    "    if \"correct\" in js['tasks'][0]['solution']:\n",
    "        true_ans = set(js['tasks'][0]['solution']['correct'])\n",
    "    else:\n",
    "        true_ans = set(js['tasks'][0]['solution']['correct_variants'][0])\n",
    "    answer = set(solver_17(js[\"tasks\"][0], True, threshold=0.6))\n",
    "    print(\"true: \", true_ans)\n",
    "    score = len(answer.intersection(true_ans)) / len(answer.union(true_ans))\n",
    "    scores.append(score)\n",
    "\n",
    "print(\"Score: \", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_tasks = os.listdir(\"/Users/edgy/Downloads/task_19/\")\n",
    "paths_to_tasks = [t for t in paths_to_tasks if t.startswith(\"T\")]\n",
    "scores_t = []\n",
    "\n",
    "for path_t in tqdm_notebook(paths_to_tasks):\n",
    "    with open(f\"/Users/edgy/Downloads/task_19/{path_t}\", \"r\") as f:\n",
    "        js = json.load(f)\n",
    "    if \"correct\" in js['tasks'][0]['solution']:\n",
    "        true_ans = set(js['tasks'][0]['solution']['correct'])\n",
    "    else: \n",
    "        true_ans = set(js['tasks'][0]['solution']['correct_variants'][0])\n",
    "    answer = set([t[\"id\"] for t in js[\"tasks\"][0][\"question\"][\"choices\"]])\n",
    "    score = len(answer.intersection(true_ans)) / len(answer.union(true_ans))\n",
    "    scores_t.append(score)\n",
    "\n",
    "print(\"Score: \", np.mean(scores_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_tasks = os.listdir(\"/Users/edgy/Downloads/task_20/\")\n",
    "paths_to_tasks = [t for t in paths_to_tasks if t.startswith(\"T\")]\n",
    "scores = []\n",
    "\n",
    "for path_t in tqdm_notebook(paths_to_tasks):\n",
    "    with open(f\"/Users/edgy/Downloads/task_20/{path_t}\", \"r\") as f:\n",
    "        js = json.load(f)\n",
    "    if \"correct\" in js['tasks'][0]['solution']:\n",
    "        true_ans = set(js['tasks'][0]['solution']['correct'])\n",
    "    else:\n",
    "        true_ans = set(js['tasks'][0]['solution']['correct_variants'][0])\n",
    "    answer = set(solver_17(js[\"tasks\"][0], True, threshold=0.5))\n",
    "    print(\"true: \", true_ans)\n",
    "    score = len(answer.intersection(true_ans)) / len(answer.union(true_ans))\n",
    "    scores.append(score)\n",
    "\n",
    "print(\"Score: \", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_tasks = os.listdir(\"/Users/edgy/Downloads/task_20/\")\n",
    "paths_to_tasks = [t for t in paths_to_tasks if t.startswith(\"T\")]\n",
    "scores_t = []\n",
    "\n",
    "for path_t in tqdm_notebook(paths_to_tasks):\n",
    "    with open(f\"/Users/edgy/Downloads/task_20/{path_t}\", \"r\") as f:\n",
    "        js = json.load(f)\n",
    "    if \"correct\" in js['tasks'][0]['solution']:\n",
    "        true_ans = set(js['tasks'][0]['solution']['correct'])\n",
    "    else: \n",
    "        true_ans = set(js['tasks'][0]['solution']['correct_variants'][0])\n",
    "    answer = set([t[\"id\"] for t in js[\"tasks\"][0][\"question\"][\"choices\"]])\n",
    "    score = len(answer.intersection(true_ans)) / len(answer.union(true_ans))\n",
    "    scores_t.append(score)\n",
    "\n",
    "print(\"Score: \", np.mean(scores_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1011 02:16:18.975415 140735486686080 deprecation_wrapper.py:119] From /Users/edgy/projects/ai-journey-2019/notebooks/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1011 02:16:19.416730 140735486686080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1011 02:16:19.457597 140735486686080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1011 02:16:19.522840 140735486686080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1011 02:16:19.523860 140735486686080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1011 02:16:19.532050 140735486686080 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1011 02:16:19.568732 140735486686080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "import tokenization\n",
    "\n",
    "rubert_folder = \"/Users/edgy/Downloads/rubert_cased_L-12_H-768_A-12_v2\"\n",
    "tokenizer_bert = tokenization.FullTokenizer(vocab_file=rubert_folder+'/vocab.txt',\n",
    "                                              do_lower_case=False)\n",
    "bert = load_trained_model_from_checkpoint(rubert_folder+'/bert_config.json',\n",
    "                                          rubert_folder+'/bert_model.ckpt',\n",
    "                                          training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_exists(w):\n",
    "    analysis = morph.parse(w)\n",
    "    if (analysis[0].methods_stack[0][0].__class__.__name__ == \"DictionaryAnalyzer\") and \\\n",
    "            (analysis[0].methods_stack[0][1] == w):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "paths_to_tasks = os.listdir(\"/Users/edgy/Downloads/task_14/\")\n",
    "paths_to_tasks = [t for t in paths_to_tasks if t.startswith(\"T\")]\n",
    "for path_t in paths_to_tasks:\n",
    "    with open(f\"/Users/edgy/Downloads/task_14/{path_t}\", \"r\") as f:\n",
    "        js = json.load(f)\n",
    "        tasks.append(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/dictionaries/freq_dict_ruscorpora.json\", \"r\") as f:\n",
    "    freq = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1054208"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solver_14(task, frequency_normalization=False):\n",
    "    def possible_variants(w):\n",
    "        w1 = re.sub(r\"[\\(\\)]\", \"\", w)\n",
    "        if w.startswith(\"(\"):\n",
    "            w2 = re.sub(r\"\\)\", \"-\", re.sub(r\"\\(\", \"\", w))\n",
    "            w3 = re.sub(r\"\\)\", \" \", re.sub(r\"\\(\", \"\", w))\n",
    "        else:\n",
    "            w2 = re.sub(r\"\\(\", \"-\", re.sub(r\"\\)\", \"\", w))\n",
    "            w3 = re.sub(r\"\\(\", \" \", re.sub(r\"\\)\", \"\", w))\n",
    "        w1_exists = word_exists(w1)\n",
    "        w2_exists = word_exists(w2)\n",
    "        w3_exists = word_exists(w3.split(\" \")[0]) and word_exists(w3.split(\" \")[1])\n",
    "        # пропишем явно что делать, если слово начинается на ПОЛ, пайморфи тупит\n",
    "        # в этих случаях, правила приблизительно реализованы (не рассмотрены заглавные,\n",
    "        # случай с У)\n",
    "        if w1.startswith(\"пол\"):\n",
    "            if w1[3] in \"леыаояиюэё\":\n",
    "                w1_exists, w2_exists, w3_exists = False, True, False\n",
    "            else:\n",
    "                w1_exists, w2_exists, w3_exists = True, False, False\n",
    "        if (not w2_exists) and (not w3_exists):\n",
    "            w1_exists = True\n",
    "        return w1, w1_exists, w2, w2_exists, w3, w3_exists\n",
    "\n",
    "    def both_together_likelihood(w1_orig, w1_cand, p1, w2_orig, w2_cand, p2, sent):\n",
    "        max_length = 512\n",
    "\n",
    "#         if p1 == 1:\n",
    "#             sent = re.sub(w1_orig, w1_cand, sent)\n",
    "#         if p2 == 1:\n",
    "#             sent = re.sub(w2_orig, w2_cand, sent)\n",
    "\n",
    "        w1_orig_shield = re.sub(\"\\)\", \"\\\\)\", re.sub(\"\\(\", \"\\\\(\", w1_orig))\n",
    "        w2_orig_shield = re.sub(\"\\)\", \"\\\\)\", re.sub(\"\\(\", \"\\\\(\", w2_orig))\n",
    "        sent = re.split(fr\"({w1_orig_shield}|{w2_orig_shield})\", sent)\n",
    "        sent = [t for t in sent if len(t) > 0]\n",
    "        tokens = [\"[CLS]\"]\n",
    "        exp_tokens = [\"[CLS]\"]\n",
    "        word_masks = [0]\n",
    "\n",
    "        w1_used = False\n",
    "        for part in sent:\n",
    "            if (part == w1_orig) and not w1_used:\n",
    "                kek = tokenizer_bert.tokenize(w1_cand)\n",
    "                exp_tokens += kek\n",
    "                tokens += [\"[MASK]\"] * len(kek)\n",
    "                word_masks += [1] * len(kek)\n",
    "                w1_used = True\n",
    "            elif part == w2_orig:\n",
    "                kek = tokenizer_bert.tokenize(w2_cand)\n",
    "                exp_tokens += kek\n",
    "                tokens += [\"[MASK]\"] * len(kek)\n",
    "                word_masks += [2] * len(kek)\n",
    "            else:\n",
    "                kek = tokenizer_bert.tokenize(part.strip())\n",
    "                exp_tokens += kek\n",
    "                tokens += kek\n",
    "                word_masks += [0] * len(kek)\n",
    "        tokens += [\"[SEP]\"]\n",
    "        exp_tokens += [\"[SEP]\"]\n",
    "        token_input = tokenizer_bert.convert_tokens_to_ids(tokens)\n",
    "        token_input = np.array(token_input + [0] * (max_length - len(token_input)))\n",
    "        exp_token_input = tokenizer_bert.convert_tokens_to_ids(exp_tokens)\n",
    "        exp_token_input = np.array(exp_token_input + [0] * (max_length - len(exp_token_input)))\n",
    "        word_masks = np.array(word_masks + [0] * (max_length - len(word_masks)))\n",
    "        mask_input = word_masks != 0\n",
    "        seg_input = np.zeros(max_length)\n",
    "\n",
    "        predicts = bert.predict([token_input.reshape(1, -1),\n",
    "                                       seg_input.reshape(1, -1),\n",
    "                                       mask_input.reshape(1, -1)])[0]\n",
    "        preds_1 = predicts[0, word_masks==1]\n",
    "        exp_token_id_1 = exp_token_input[word_masks==1]\n",
    "        subprobas_1 = []\n",
    "        for i, t_id in enumerate(exp_token_id_1):\n",
    "            subprobas_1.append(preds_1[i, t_id])\n",
    "        preds_2 = predicts[0, word_masks==2]\n",
    "        exp_token_id_2 = exp_token_input[word_masks==2]\n",
    "        subprobas_2 = []\n",
    "        for i, t_id in enumerate(exp_token_id_2):\n",
    "            subprobas_2.append(preds_2[i, t_id])\n",
    "        print(sent)\n",
    "        norm_1, norm_2 = 1, 1\n",
    "        if frequency_normalization:\n",
    "            norm_1 /= freq[w1_cand]\n",
    "            norm_2 /= freq[w2_cand]\n",
    "        print(subprobas_1, norm_1, subprobas_2, norm_2)\n",
    "        print(min(np.mean(subprobas_1) * norm_1,\n",
    "                   np.mean(subprobas_2) * norm_2))\n",
    "        if p1 == 1:\n",
    "            return np.mean(subprobas_2) * norm_2\n",
    "        if p2 == 1:\n",
    "            return np.mean(subprobas_1) * norm_1\n",
    "        return min(np.mean(subprobas_1) * norm_1,\n",
    "                   np.mean(subprobas_2) * norm_2)\n",
    "    text = task[\"text\"]\n",
    "    tmp = re.split(r\"[\\n\\.\\?\\!]+\", text)\n",
    "    sentences = []\n",
    "    word_pairs = []\n",
    "    possibilities = []\n",
    "    together_variants = []\n",
    "    for s in tmp:\n",
    "        if len(s) < 1:\n",
    "            continue\n",
    "        if not s[-1] in \".?!\":\n",
    "            s += \".\"\n",
    "        words = re.findall(\"[А-ЯЁ]*\\([А-ЯЁ]+\\)[А-ЯЁ]*\", s)\n",
    "        if len(words) == 2:\n",
    "            w1_1, t1_1, w1_2, t1_2, w1_3, t1_3 = possible_variants(words[0].lower())\n",
    "            w2_1, t2_1, w2_2, t2_2, w2_3, t2_3 = possible_variants(words[1].lower())\n",
    "            if t1_1 and t2_1:\n",
    "                word_pairs.append(words)\n",
    "                sentences.append(s)\n",
    "                possibilities.append([[t1_1, t1_2, t1_3], [t2_1, t2_2, t2_3]])\n",
    "                together_variants.append([w1_1, w2_1])\n",
    "                if not(t1_2 or t1_3 or t2_2 or t2_3):\n",
    "                    # У нас есть досрочный ответ\n",
    "                    return w1_1+w2_1\n",
    "    max_likelihood = 0\n",
    "    if len(together_variants) == 1:\n",
    "        w1_cand, w2_cand = together_variants[0]\n",
    "        return w1_cand + w2_cand\n",
    "    elif len(together_variants) == 0:\n",
    "        return w1_1 + w2_1\n",
    "    for s, word_pair, possibility, together_variant in zip(sentences,\n",
    "                                                           word_pairs,\n",
    "                                                           possibilities,\n",
    "                                                           together_variants):\n",
    "        w1_orig, w2_orig = word_pair\n",
    "        w1_cand, w2_cand = together_variant\n",
    "        p1, p2 = possibility\n",
    "        likelihood = both_together_likelihood(w1_orig, w1_cand, sum(p1),\n",
    "                                              w2_orig, w2_cand, sum(p2),\n",
    "                                              s)\n",
    "        if likelihood > max_likelihood:\n",
    "            max_likelihood = likelihood\n",
    "            answer = w1_cand + w2_cand\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task # 0\n",
      "['Группами и ', '(ПО)ОДИНОЧКЕ', ' бродили туристы в курортных шапочках, ', '(И)ТАК', ' было почти весь год.']\n",
      "[0.021590982] 0.0013477088948787063 [9.774301e-07, 7.4745697e-07] 0.0014970059880239522\n",
      "1.2910831259715795e-09\n",
      "['(НЕ)СМОТРЯ', ' на прошедшие годы, Николай не смог простить человеку, которого считал другом, его ', '(МАЛО)ДУШИЕ', '.']\n",
      "[0.0006111483] 4.504301608035674e-05 [0.00077143055, 0.00013530701, 2.719771e-05] 0.003125\n",
      "2.752796310808448e-08\n",
      "['(С)НАЧАЛА', ' дети шли в колонне ', '(ПО)ДВОЕ', ', но потом стали двигаться беспорядочными кучками.']\n",
      "[0.00016406883] 4.3863496797964735e-05 [2.819315e-06, 1.4796928e-05] 0.05\n",
      "7.196632505975666e-09\n",
      "['Я всё ', 'ТАК(ЖЕ)', ' очень жалел о сказанном, хотел забыть обо всём, ', '(ПРИ)ТОМ', ' как можно скорее.']\n",
      "[0.00041144894] 1.0867675186924013e-05 [1.7098411e-05] 0.0001312163758037003\n",
      "2.243591557912384e-09\n",
      "несмотрямалодушие\n",
      "['несмотрямалодушие', 'малодушиенесмотря']\n",
      "Task # 1\n",
      "['Собираясь ', '(НА)ВСТРЕЧУ', ' с представителем фирмы, парень волновался, ', '(НЕ)СМОТРЯ', ' на большой опыт работы.']\n",
      "[3.4215332e-06] 9.040773890245005e-05 [0.71765965] 4.504301608035674e-05\n",
      "3.093330770488775e-10\n",
      "['(ВО)ВРЕМЯ', ' урока физкультуры ', '(ОТО)ВСЮДУ', ' слышатся весёлые крики и оживлённый смех.']\n",
      "[8.462861e-08] 0.00017608733932030288 [2.0621119e-05, 4.3989687e-05, 5.088959e-05, 0.0045774775] 0.0006622516556291391\n",
      "1.49020267472554e-11\n",
      "навстречунесмотря\n",
      "['отчегооттого', 'оттогоотчего']\n",
      "Task # 2\n",
      "['И прежде Андрей ничего ', 'ТО(ЖЕ)', ' не ощущал, ', 'ЗА(ТО)', ' был счастлив и спокоен.']\n",
      "[0.00016686841] 7.72153071624919e-06 [0.049573466] 7.887679444707367e-05\n",
      "1.288479573727938e-09\n",
      "['(НА)ОБОРОТ', ', хозяйки Роман не боялся, ', 'ЧТО(БЫ)', ' та ни замышляла против него.']\n",
      "[1.0440548e-06] 7.704160246533128e-05 [0.1373544] 3.751500600240096e-06\n",
      "8.043565361793114e-11\n",
      "тожезато\n",
      "['тожезато', 'затотоже']\n",
      "Task # 3\n",
      "['А небо в те дни льёт на землю ласкающий свет, и прозрачная голубизна его бывает притягательна – не ', '(ОТ)ТОГО', ' ли и стар и млад так ', '(ПО)ДОЛГУ', ' смотрят на небо.']\n",
      "[0.0005272694] 9.473285335354301e-05 [0.00010825274] 0.0004764173415912339\n",
      "4.994973300152619e-08\n",
      "['ТАК(ЖЕ)', ' было и в прошлый раз, три месяца тому назад, когда она с ним разговаривала, а потом речь её прервалась на ', '(ПОЛУ)СЛОВЕ', '.']\n",
      "[5.522411e-07] 1.0867675186924013e-05 [0.000115444556, 1.5497511e-05, 0.04297667] 0.002386634844868735\n",
      "6.001576793061685e-12\n",
      "['Но он ничего не сделал, ', '(ПО)ТОМУ', ' что и не мог ничего сделать, просто не было у него ничего такого затаённого, ', 'ЧТО(Б)', ' он мог вытащить наружу.']\n",
      "[0.80798334] 7.1825664746527225e-06 [0.0022322775] 1.905378884591201e-05\n",
      "4.253334476000706e-08\n",
      "оттогоподолгу\n",
      "['оттогоподолгу', 'подолгуоттого']\n",
      "Task # 4\n",
      "['ЧТО(БЫ)', ' прикасаться к шедеврам, нужно понимать всю ответственность: позолота от шедевра остаётся на пальцах ', '(НА)ВСЕГДА', '.']\n",
      "[0.000111433554] 3.751500600240096e-06 [0.001196578] 7.732755954222085e-05\n",
      "4.1804304353255244e-10\n",
      "['(НЕ)СМОТРЯ', ' на уже данное Юле обещание, пришлось повторить ', 'ТО(ЖЕ)', ' самое ещё раз её брату.']\n",
      "[0.0010417005] 4.504301608035674e-05 [0.0024782626] 7.72153071624919e-06\n",
      "1.9135981116212716e-08\n",
      "несмотрятоже\n",
      "['чтобынавсегда', 'навсегдачтобы']\n",
      "Task # 5\n",
      "['ЧТО(БЫ)', ' мне надеть, ', 'ЧТО(БЫ)', ' не замёрзнуть.']\n",
      "[0.0002422684] 3.751500600240096e-06 [0.7751072] 3.751500600240096e-06\n",
      "9.088700656158043e-10\n",
      "['Это письмо затерялось, ', '(ПО)ТОМУ', ' что оно ', 'ТАК(ЖЕ)', ', как и другая корреспонденция, было отправлено по старому адресу.']\n",
      "[0.6522664] 7.1825664746527225e-06 [0.08650925] 1.0867675186924013e-05\n",
      "9.401544307992885e-07\n",
      "['Отец ', '(ДО)ПОЗДНА', ' сидел в библиотеке, которая была снизу ', '(ДО)ВЕРХУ', ' заполнена книгами.']\n",
      "[7.191767e-07, 9.032443e-06, 0.0008768624] 0.003246753246753247 [1.3467221e-05, 0.00012120122] 0.0015220700152207\n",
      "1.0248740025423184e-07\n",
      "потомутакже\n",
      "['допозднадоверху', 'доверхудопоздна']\n",
      "Task # 6\n",
      "['(И)ТАК', ', подытожим всё сказанное: лес – наш целитель, наше богатство и, ', '(НА)КОНЕЦ', ', лучший наряд земли.']\n",
      "[1.3395635e-05, 1.621118e-05] 0.0014970059880239522 [0.0919246] 1.8980374292981057e-05\n",
      "2.216078874896961e-08\n",
      "['(ОТ)ТОГО', ' места, где ребята распрощались, их отделяли теперь по меньшей мере семь кварталов, ', '(ПО)ЭТОМУ', ' возвращаться уже не было никакого смысла.']\n",
      "[7.147257e-08] 9.473285335354301e-05 [0.037197165] 3.402170584833123e-05\n",
      "6.770800500620689e-12\n",
      "итакнаконец\n",
      "итакнаконец\n",
      "Task # 7\n",
      "['(ПОД)МЫШКОЙ', ' у господина была изысканная трость, ', '(ЗА)ТО', ' шляпа его выглядела старой и повидавшей виды.']\n",
      "[8.656361e-08, 9.622318e-06, 0.00082248874] 0.013157894736842105 [0.008262321] 7.887679444707367e-05\n",
      "6.517054230129894e-07\n",
      "['Софья Львовна, сама не зная ', '(ОТ)ЧЕГО', ', минутку плакала молча, потом вытерла слёзы и сказала: «Рита ', 'ТО(ЖЕ)', ' с нами, и Володя тут».']\n",
      "[7.615861e-05] 0.00010733068584308254 [0.022143548] 7.72153071624919e-06\n",
      "8.1741561125766e-09\n",
      "подмышкойзато\n",
      "['отчеготоже', 'тожеотчего']\n",
      "Task # 8\n",
      "['(В)ТАЙНЕ', ' он желал, чтобы путешествие длилось бесконечно, чтобы ', '(ТАК)ЖЕ', ' думала и Маша.']\n",
      "[2.2083043e-06] 0.0007147962830593281 [0.0020026397] 1.0867675186924013e-05\n",
      "1.5784877019168297e-09\n",
      "['Солнце палило ', '(ВО)ВСЮ', ', и Варя, исходив полдеревни из конца ', '(В)КОНЕЦ', ', повернула обратно.']\n",
      "[0.002156423, 3.2623097e-06] 0.0006393861892583121 [1.31056495e-05, 6.453009e-07] 0.0008984725965858042\n",
      "6.177426113816931e-09\n",
      "['Дожди шли беспрерывно ', '(С)НАЧАЛА', ' лета, и трава, ', '(С)НАЧАЛА', ' яркая и зелёная, начала жухнуть.']\n",
      "[9.352032e-06] 4.3863496797964735e-05 [0.00048455346] 4.3863496797964735e-05\n",
      "4.1021282858540366e-10\n",
      "['(ЧТО)БЫ', ' не попасть ', '(В)ПРОСАК', ', нужно быть готовым к разным неожиданностям.']\n",
      "[0.00026865973] 3.751500600240096e-06 [0.00010274046, 1.3438425e-07, 0.0010839767] 0.004739336492890996\n",
      "1.0078771347722257e-09\n",
      "вовсювконец\n",
      "['чтобывпросак', 'впросакчтобы']\n",
      "Task # 9\n",
      "такжечтобы\n",
      "['такжечтобы', 'чтобытакже']\n",
      "Task # 10\n",
      "['Гость, пришедший ', '(ВО)ВРЕМЯ', ' обеда, осведомился ', '(НА)СЧЁТ', ' здоровья моего отца.']\n",
      "[1.6758357e-06] 0.00017608733932030288 [0.09594521] 0.001692047377326565\n",
      "2.9509345541374566e-10\n",
      "['Она старалась ', '(НА)ЧИСТО', ' вытереть ', '(ПОЛУ)ПРОЗРАЧНОЕ', ' стекло.']\n",
      "[1.2997789e-05, 0.00052817806] 0.0006289308176100629 [0.0003256538, 0.06702873] 0.03225806451612903\n",
      "1.701810792580528e-07\n",
      "начистополупрозрачное\n",
      "['начистополупрозрачное', 'полупрозрачноеначисто']\n",
      "Task # 11\n",
      "чтобысначала\n",
      "['чтобысначала', 'сначалачтобы']\n",
      "Task # 12\n",
      "['Сна ', '(ПО)НАЧАЛУ', ' не было ни в одном глазу, однако, как только я решил утром во ', 'ЧТО(БЫ)', ' то ни стало всё выяснить, мне удалось заснуть.']\n",
      "[0.0017191258] 0.00038714672861014324 [4.3526863e-05] 3.751500600240096e-06\n",
      "1.6329105270821472e-10\n",
      "['(ПОД)МЫШКОЙ', ' у этого господина была зажата свежая газета, ', '(ОТ)ТОГО', ' движения его были немного скованными.']\n",
      "[4.4069576e-08, 4.3939417e-06, 0.00081084564] 0.013157894736842105 [2.544709e-05] 9.473285335354301e-05\n",
      "2.4106755014147233e-09\n",
      "['(НЕ)СМОТРЯ', ' на то что отец всегда был настроен ', '(ПОЛУ)ШУТЛИВО', ', он был человек отнюдь не легкомысленный.']\n",
      "[0.00021873468] 4.504301608035674e-05 [7.7305293e-07, 8.059144e-06, 0.00039057943] 0.015384615384615385\n",
      "9.852469870066807e-09\n",
      "несмотряполушутливо\n",
      "['несмотряполушутливо', 'полушутливонесмотря']\n",
      "Task # 13\n",
      "['Причиной выбрасывания китов на берег могут быть гидролокаторы военных, достаточно мощные, ', 'ЧТО(БЫ)', ' проникнуть ', '(В)ГЛУБЬ', ' океана и напугать животных.']\n",
      "[0.9747608] 3.751500600240096e-06 [0.34955] 0.0009652509652509653\n",
      "3.656815616738181e-06\n",
      "['Недолго пройдя в темноте, Костя понял, что ', '(СО)ВСЕМ', ' сбился с пути, наверно, ', 'ТО(ЖЕ)', ' понял и командир.']\n",
      "[0.00056440855] 1.1442825920289274e-05 [0.00035654698] 7.72153071624919e-06\n",
      "2.7530884693842166e-09\n",
      "['Новобранцев до принятия присяги не полагалось отпускать в город ', '(ПО)ОДИНОЧКЕ', ', но инструктор, ', '(В)ВИДУ', ' моего необычайного успеха по словесности, сделал для меня исключение.']\n",
      "[6.987365e-05] 0.0013477088948787063 [0.36560205] 0.00028368794326241134\n",
      "9.416933637426167e-08\n",
      "['Никита сказал, ', 'ЧТО(БЫ)', ' мы шли ', '(ПО)ДВОЕ', '.']\n",
      "[0.21487334] 3.751500600240096e-06 [1.95791e-05, 3.1421438e-05] 0.05\n",
      "8.060974778891468e-07\n",
      "чтобывглубь\n",
      "['поодиночкеввиду', 'ввидупоодиночке']\n",
      "Task # 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Причиной выбрасывания китов на берег могут быть гидролокаторы военных, достаточно мощные, ', 'ЧТО(БЫ)', ' проникнуть ', '(В)ГЛУБЬ', ' океана и напугать животных.']\n",
      "[0.9747608] 3.751500600240096e-06 [0.34955] 0.0009652509652509653\n",
      "3.656815616738181e-06\n",
      "['Недолго пройдя в темноте, Костя понял, что ', '(СО)ВСЕМ', ' сбился с пути, наверно, ', 'ТО(ЖЕ)', ' понял и командир.']\n",
      "[0.00056440855] 1.1442825920289274e-05 [0.00035654698] 7.72153071624919e-06\n",
      "2.7530884693842166e-09\n",
      "['Новобранцев до принятия присяги не полагалось отпускать в город ', '(ПО)ОДИНОЧКЕ', ', но инструктор, ', '(В)ВИДУ', ' моего необычайного успеха по словесности, сделал для меня исключение.']\n",
      "[6.987365e-05] 0.0013477088948787063 [0.36560205] 0.00028368794326241134\n",
      "9.416933637426167e-08\n",
      "['Никита сказал, ', 'ЧТО(БЫ)', ' мы шли ', '(ПО)ДВОЕ', '.']\n",
      "[0.21487334] 3.751500600240096e-06 [1.95791e-05, 3.1421438e-05] 0.05\n",
      "8.060974778891468e-07\n",
      "чтобывглубь\n",
      "['поодиночкеввиду', 'ввидупоодиночке']\n",
      "Task # 15\n",
      "['Петр I хотел, ', 'ЧТО(БЫ)', ' Россия, получившая выход на Балтику, стала ', 'ТАК(ЖЕ)', ' сильной тихоокеанской державой.']\n",
      "[0.98951894] 3.751500600240096e-06 [0.00041270914] 1.0867675186924013e-05\n",
      "4.4851888572692565e-09\n",
      "['(ВО)ВРЕМЯ', ' плавания экспедиция открыла новые острова и прошла пролив, названный ', '(В)ПОСЛЕДСТВИИ', ' Беринговым.']\n",
      "[1.1611938e-08] 0.00017608733932030288 [0.5389414] 9.928514694201747e-05\n",
      "2.0447152804629466e-12\n",
      "['В ', 'ТО(ЖЕ)', ' самое время в Петербурге уже подготавливали новую экспедицию, которой, кроме плавания в Тихом океане, предстояли и ', 'СО(ВСЕМ)', ' иные маршруты.']\n",
      "[0.0019605013] 7.72153071624919e-06 [0.41000074] 1.1442825920289274e-05\n",
      "1.513807106604687e-08\n",
      "тожесовсем\n",
      "['чтобытакже', 'такжечтобы']\n",
      "Task # 16\n",
      "['Теперь, даже ', '(НЕ)СМОТРЯ', ' на седину, морщины и очки, его ', '(НА)ЧИСТО', ' лишённое эмоций лицо кажется прекрасным.']\n",
      "[0.98087686] 4.504301608035674e-05 [4.838296e-07, 0.0001007038] 0.0006289308176100629\n",
      "3.182000949914397e-08\n",
      "['Илье Антонычу наскучило носить ружьё ', '(ПОД)МЫШКОЙ', ', ', '(ПО)ЭТОМУ', ' он перекинул его на плечо.']\n",
      "[7.894238e-06, 0.00012953689, 0.003978688] 0.013157894736842105 [0.00182377] 3.402170584833123e-05\n",
      "6.204776643203073e-08\n",
      "['(НА)КОНЕЦ', ' прошла неделя, а комната всё ', 'ТАК(ЖЕ)', ' была заперта.']\n",
      "[9.930327e-07] 1.8980374292981057e-05 [0.0006739774] 1.0867675186924013e-05\n",
      "1.8848132324060916e-11\n",
      "подмышкойпоэтому\n",
      "['несмотряначисто', 'начистонесмотря']\n",
      "Task # 17\n",
      "подальшевмиг\n",
      "['подальшевмиг', 'вмигподальше']\n",
      "Task # 18\n",
      "['ТО(ЖЕ)', ' тихое мерцание зеленоватого прозрачного неба, ', 'ТАК(ЖЕ)', ' тянет с реки холодной влагой.']\n",
      "[1.4368223e-07] 7.72153071624919e-06 [7.5075775e-05] 1.0867675186924013e-05\n",
      "1.1094467429152799e-12\n",
      "['(ПОЛ)ДНЯ', ' ушло на сборы и подготовку к выступлению, ', '(ПРИ)ЧЁМ', ' оказалось, что ещё далеко не всё готово.']\n",
      "[6.3048516e-05, 1.6333253e-05] 0.001375515818431912 [0.0010269227] 0.0012626262626262627\n",
      "5.459543819567432e-08\n",
      "полдняпричём\n",
      "['полдняпричём', 'причёмполдня', 'полдняпричем', 'причемполдня']\n",
      "Task # 19\n",
      "поистинетакже\n",
      "['поистинетакже', 'такжепоистине']\n",
      "Task # 20\n",
      "['В дальнем конце коридора стояло странное сооружение, ', '(НА)ПОДОБИЕ', ' огромной рельсы, уходящей под углом ', '(В)ВЕРХ', '.']\n",
      "[0.07216842] 0.0006242197253433209 [0.047921672] 6.288517167651868e-05\n",
      "3.013562599887879e-06\n",
      "['Всё ', 'ТАК(ЖЕ)', ' горела сальная свеча на столе, росли тихие герани на подоконниках, тикали часы, ', '(ПРИ)ЧЁМ', ' звук их с годами совсем не изменился.']\n",
      "[0.00063852995] 1.0867675186924013e-05 [0.0128590185] 0.0012626262626262627\n",
      "6.93933608672264e-09\n",
      "наподобиевверх\n",
      "['наподобиевверх', 'вверхнаподобие']\n",
      "Task # 21\n",
      "['Дизайнеры обратили внимание ', '(НА)ПОДОБИЕ', ' планировок соседних комнат, которые должны были ', '(В)ПОСЛЕДСТВИИ', ' преобразиться в сказочные спальни для близнецов.']\n",
      "[6.5564636e-06] 0.0006242197253433209 [0.23068413] 9.928514694201747e-05\n",
      "4.092673927321146e-09\n",
      "['Как только я ступил за порог, он ', '(ТОТ)ЧАС', ' же меня окликнул и помахал на прощание рукой, я сделал ', '(ТО)ЖЕ', ', улыбнувшись в ответ.']\n",
      "[0.04935985] 5.0352467270896274e-05 [0.0001224607] 7.72153071624919e-06\n",
      "9.455840313326698e-10\n",
      "['(НЕ)СМОТРЯ', ' на долгую дружбу, Агафонов ударил его между лопаток, он ', '(ЗА)ТО', ' еще долго на него злился.']\n",
      "[0.0006065199] 4.504301608035674e-05 [4.9725342e-05] 7.887679444707367e-05\n",
      "3.922175599534213e-09\n",
      "['Он периодически думал, ', 'ЧТО(БЫ)', ' сделать, ', 'ЧТО(БЫ)', ' избавиться от хандры.']\n",
      "[0.00046088806] 3.751500600240096e-06 [0.62825227] 3.751500600240096e-06\n",
      "1.7290218164241513e-09\n",
      "['(В)СЛЕДСТВИЕ', ' затяжного кризиса утечка кадров достигла критического уровня, ', '(В)СЛЕД', ' за чем компания перестала существовать.']\n",
      "[3.908298e-05] 0.00010954102311315588 [0.97093767] 7.838833581563063e-05\n",
      "4.281189719308688e-09\n",
      "вследствиевслед\n",
      "['вследствиевслед', 'вследвследствие']\n",
      "Task # 22\n",
      "['Максимка, ', '(ЧТО)БЫ', ' ни говорили все вокруг, верил в успех, и ', '(ПО)НЕМНОГУ', ' дело пошло.']\n",
      "[0.00010344975] 3.751500600240096e-06 [0.00017759876] 0.00034352456200618345\n",
      "3.8809178893082347e-10\n",
      "['Подошедший к костру ', '(С)НАЧАЛА', ' застенчиво постоял, а потом придвинулся к огню ', '(ПО)БЛИЖЕ', '.']\n",
      "[0.031601578] 4.3863496797964735e-05 [0.0025600425] 0.00026954177897574127\n",
      "6.900384213845685e-07\n",
      "['Погода, как показалось Наташе, ', 'БУД(ТО)', ' начала меняться, снег словно перестал валить сплошной стеной – но нет: утром было всё ', 'ТО(ЖЕ)', '.']\n",
      "[0.000584513] 1.302252897512697e-05 [0.0020889747] 7.72153071624919e-06\n",
      "7.611837572568421e-09\n",
      "сначалапоближе\n",
      "['сначалапоближе', 'поближесначала']\n",
      "Task # 23\n",
      "['(В)ПОСЛЕДСТВИИ', ' учёные установили, что магний играет важную роль в регуляции уровня калия в организме, а ', 'ТАК(ЖЕ)', ' регулирует работу надпочечников.']\n",
      "[3.0691674e-05] 9.928514694201747e-05 [0.9852594] 1.0867675186924013e-05\n",
      "3.0472273233531943e-09\n",
      "['Физические свойства межзвёздного газа существенно зависят ', '(ОТ)ТОГО', ', находится ли он в сравнительной близости от горячих звёзд или, ', '(НА)ОБОРОТ', ', достаточно удалён от них.']\n",
      "[0.14381863] 9.473285335354301e-05 [0.6937293] 7.704160246533128e-05\n",
      "1.3624349352806614e-05\n",
      "оттогонаоборот\n",
      "['впоследствиитакже', 'такжевпоследствии']\n",
      "Task # 24\n",
      "тожепоэтому\n",
      "['тожепоэтому', 'поэтомутоже']\n",
      "Task # 25\n",
      "насчёттакже\n",
      "['насчёттакже', 'такженасчёт']\n",
      "Task # 26\n",
      "['Рисунки известных мастеров графики ', '(ПО)ВСЮДУ', ' в музеях ', 'ТАК(ЖЕ)', ' бережно хранятся, как и картины живописцев.']\n",
      "[0.00024184713] 0.00024354603019970775 [0.0015113261] 1.0867675186924013e-05\n",
      "1.6424600718343097e-08\n",
      "['Отстегнув ремни, они надели ', '(ТЕРМО)КОСТЮМЫ', ', потому что, ', '(НЕ)СМОТРЯ', ' на полдень, было холодно.']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'термокостюмы'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-989130c2c3d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Task # {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tasks\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver_14\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequency_normalization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"correct\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"solution\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-84e5f9e45d4a>\u001b[0m in \u001b[0;36msolver_14\u001b[0;34m(task, frequency_normalization)\u001b[0m\n\u001b[1;32m    132\u001b[0m         likelihood = both_together_likelihood(w1_orig, w1_cand, sum(p1),\n\u001b[1;32m    133\u001b[0m                                               \u001b[0mw2_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2_cand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                                               s)\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlikelihood\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_likelihood\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mmax_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlikelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-84e5f9e45d4a>\u001b[0m in \u001b[0;36mboth_together_likelihood\u001b[0;34m(w1_orig, w1_cand, p1, w2_orig, w2_cand, p2, sent)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mnorm_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfrequency_normalization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mnorm_1\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1_cand\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mnorm_2\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw2_cand\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubprobas_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubprobas_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'термокостюмы'"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for i, task in enumerate(tasks):\n",
    "    print(f\"Task # {i}\")\n",
    "    task = task[\"tasks\"][0]\n",
    "    pred = solver_14(task, frequency_normalization=True)\n",
    "    print(pred)\n",
    "    if \"correct\" in task[\"solution\"]:\n",
    "        answer = task[\"solution\"][\"correct\"]\n",
    "        print(answer)\n",
    "        scores.append(answer == pred)\n",
    "    else:\n",
    "        answer = task[\"solution\"][\"correct_variants\"]\n",
    "        print(answer)\n",
    "        scores.append(any([pred == t for t in answer]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5769230769230769"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task # 0\n",
      "['Группами и ', '(ПО)ОДИНОЧКЕ', ' бродили туристы в курортных шапочках, ', '(И)ТАК', ' было почти весь год.']\n",
      "[0.021590982] 1 [9.774301e-07, 7.4745697e-07] 1\n",
      "7.474569656551466e-07\n",
      "['(НЕ)СМОТРЯ', ' на прошедшие годы, Николай не смог простить человеку, которого считал другом, его ', '(МАЛО)ДУШИЕ', '.']\n",
      "[0.0006111483] 1 [0.00077143055, 0.00013530701, 2.719771e-05] 1\n",
      "2.7197709641768597e-05\n",
      "['(С)НАЧАЛА', ' дети шли в колонне ', '(ПО)ДВОЕ', ', но потом стали двигаться беспорядочными кучками.']\n",
      "[0.00016406883] 1 [2.819315e-06, 1.4796928e-05] 1\n",
      "2.819314886437496e-06\n",
      "['Я всё ', 'ТАК(ЖЕ)', ' очень жалел о сказанном, хотел забыть обо всём, ', '(ПРИ)ТОМ', ' как можно скорее.']\n",
      "[0.00041144894] 1 [1.7098411e-05] 1\n",
      "1.7098411262850277e-05\n",
      "несмотрямалодушие\n",
      "['несмотрямалодушие', 'малодушиенесмотря']\n",
      "Task # 1\n",
      "['Собираясь ', '(НА)ВСТРЕЧУ', ' с представителем фирмы, парень волновался, ', '(НЕ)СМОТРЯ', ' на большой опыт работы.']\n",
      "[3.4215332e-06] 1 [0.71765965] 1\n",
      "3.4215331652376335e-06\n",
      "['(ВО)ВРЕМЯ', ' урока физкультуры ', '(ОТО)ВСЮДУ', ' слышатся весёлые крики и оживлённый смех.']\n",
      "[8.462861e-08] 1 [2.0621119e-05, 4.3989687e-05, 5.088959e-05, 0.0045774775] 1\n",
      "8.462860989766341e-08\n",
      "навстречунесмотря\n",
      "['отчегооттого', 'оттогоотчего']\n",
      "Task # 2\n",
      "['И прежде Андрей ничего ', 'ТО(ЖЕ)', ' не ощущал, ', 'ЗА(ТО)', ' был счастлив и спокоен.']\n",
      "[0.00016686841] 1 [0.049573466] 1\n",
      "0.0001668684126343578\n",
      "['(НА)ОБОРОТ', ', хозяйки Роман не боялся, ', 'ЧТО(БЫ)', ' та ни замышляла против него.']\n",
      "[1.0440548e-06] 1 [0.1373544] 1\n",
      "1.0440547839607461e-06\n",
      "тожезато\n",
      "['тожезато', 'затотоже']\n",
      "Task # 3\n",
      "['А небо в те дни льёт на землю ласкающий свет, и прозрачная голубизна его бывает притягательна – не ', '(ОТ)ТОГО', ' ли и стар и млад так ', '(ПО)ДОЛГУ', ' смотрят на небо.']\n",
      "[0.0005272694] 1 [0.00010825274] 1\n",
      "0.00010825273784575984\n",
      "['ТАК(ЖЕ)', ' было и в прошлый раз, три месяца тому назад, когда она с ним разговаривала, а потом речь её прервалась на ', '(ПОЛУ)СЛОВЕ', '.']\n",
      "[5.522411e-07] 1 [0.000115444556, 1.5497511e-05, 0.04297667] 1\n",
      "5.52241090190364e-07\n",
      "['Но он ничего не сделал, ', '(ПО)ТОМУ', ' что и не мог ничего сделать, просто не было у него ничего такого затаённого, ', 'ЧТО(Б)', ' он мог вытащить наружу.']\n",
      "[0.80798334] 1 [0.0022322775] 1\n",
      "0.0022322775330394506\n",
      "потомучтоб\n",
      "['оттогоподолгу', 'подолгуоттого']\n",
      "Task # 4\n",
      "['ЧТО(БЫ)', ' прикасаться к шедеврам, нужно понимать всю ответственность: позолота от шедевра остаётся на пальцах ', '(НА)ВСЕГДА', '.']\n",
      "[0.000111433554] 1 [0.001196578] 1\n",
      "0.00011143355368403718\n",
      "['(НЕ)СМОТРЯ', ' на уже данное Юле обещание, пришлось повторить ', 'ТО(ЖЕ)', ' самое ещё раз её брату.']\n",
      "[0.0010417005] 1 [0.0024782626] 1\n",
      "0.0010417004814371467\n",
      "несмотрятоже\n",
      "['чтобынавсегда', 'навсегдачтобы']\n",
      "Task # 5\n",
      "['ЧТО(БЫ)', ' мне надеть, ', 'ЧТО(БЫ)', ' не замёрзнуть.']\n",
      "[0.0002422684] 1 [0.7751072] 1\n",
      "0.00024226840469054878\n",
      "['Это письмо затерялось, ', '(ПО)ТОМУ', ' что оно ', 'ТАК(ЖЕ)', ', как и другая корреспонденция, было отправлено по старому адресу.']\n",
      "[0.6522664] 1 [0.08650925] 1\n",
      "0.08650925010442734\n",
      "['Отец ', '(ДО)ПОЗДНА', ' сидел в библиотеке, которая была снизу ', '(ДО)ВЕРХУ', ' заполнена книгами.']\n",
      "[7.191767e-07, 9.032443e-06, 0.0008768624] 1 [1.3467221e-05, 0.00012120122] 1\n",
      "7.191766826508683e-07\n",
      "потомутакже\n",
      "['допозднадоверху', 'доверхудопоздна']\n",
      "Task # 6\n",
      "['(И)ТАК', ', подытожим всё сказанное: лес – наш целитель, наше богатство и, ', '(НА)КОНЕЦ', ', лучший наряд земли.']\n",
      "[1.3395635e-05, 1.621118e-05] 1 [0.0919246] 1\n",
      "1.339563459623605e-05\n",
      "['(ОТ)ТОГО', ' места, где ребята распрощались, их отделяли теперь по меньшей мере семь кварталов, ', '(ПО)ЭТОМУ', ' возвращаться уже не было никакого смысла.']\n",
      "[7.147257e-08] 1 [0.037197165] 1\n",
      "7.147257008455199e-08\n",
      "итакнаконец\n",
      "итакнаконец\n",
      "Task # 7\n",
      "['(ПОД)МЫШКОЙ', ' у господина была изысканная трость, ', '(ЗА)ТО', ' шляпа его выглядела старой и повидавшей виды.']\n",
      "[8.656361e-08, 9.622318e-06, 0.00082248874] 1 [0.008262321] 1\n",
      "8.656360961367682e-08\n",
      "['Софья Львовна, сама не зная ', '(ОТ)ЧЕГО', ', минутку плакала молча, потом вытерла слёзы и сказала: «Рита ', 'ТО(ЖЕ)', ' с нами, и Володя тут».']\n",
      "[7.615861e-05] 1 [0.022143548] 1\n",
      "7.615861250087619e-05\n",
      "подмышкойзато\n",
      "['отчеготоже', 'тожеотчего']\n",
      "Task # 8\n",
      "['(В)ТАЙНЕ', ' он желал, чтобы путешествие длилось бесконечно, чтобы ', '(ТАК)ЖЕ', ' думала и Маша.']\n",
      "[2.2083043e-06] 1 [0.0020026397] 1\n",
      "2.2083042949816445e-06\n",
      "['Солнце палило ', '(ВО)ВСЮ', ', и Варя, исходив полдеревни из конца ', '(В)КОНЕЦ', ', повернула обратно.']\n",
      "[0.002156423, 3.2623097e-06] 1 [1.31056495e-05, 6.453009e-07] 1\n",
      "6.453008722928644e-07\n",
      "['Дожди шли беспрерывно ', '(С)НАЧАЛА', ' лета, и трава, ', '(С)НАЧАЛА', ' яркая и зелёная, начала жухнуть.']\n",
      "[9.352032e-06] 1 [0.00048455346] 1\n",
      "9.352032066090032e-06\n",
      "['(ЧТО)БЫ', ' не попасть ', '(В)ПРОСАК', ', нужно быть готовым к разным неожиданностям.']\n",
      "[0.00026865973] 1 [0.00010274046, 1.3438425e-07, 0.0010839767] 1\n",
      "1.343842512824267e-07\n",
      "чтобывпросак\n",
      "['чтобывпросак', 'впросакчтобы']\n",
      "Task # 9\n",
      "такжечтобы\n",
      "['такжечтобы', 'чтобытакже']\n",
      "Task # 10\n",
      "['Гость, пришедший ', '(ВО)ВРЕМЯ', ' обеда, осведомился ', '(НА)СЧЁТ', ' здоровья моего отца.']\n",
      "[1.6758357e-06] 1 [0.09594521] 1\n",
      "1.6758357332946616e-06\n",
      "['Она старалась ', '(НА)ЧИСТО', ' вытереть ', '(ПОЛУ)ПРОЗРАЧНОЕ', ' стекло.']\n",
      "[1.2997789e-05, 0.00052817806] 1 [0.0003256538, 0.06702873] 1\n",
      "1.2997788871871307e-05\n",
      "начистополупрозрачное\n",
      "['начистополупрозрачное', 'полупрозрачноеначисто']\n",
      "Task # 11\n",
      "чтобысначала\n",
      "['чтобысначала', 'сначалачтобы']\n",
      "Task # 12\n",
      "['Сна ', '(ПО)НАЧАЛУ', ' не было ни в одном глазу, однако, как только я решил утром во ', 'ЧТО(БЫ)', ' то ни стало всё выяснить, мне удалось заснуть.']\n",
      "[0.0017191258] 1 [4.3526863e-05] 1\n",
      "4.352686300990172e-05\n",
      "['(ПОД)МЫШКОЙ', ' у этого господина была зажата свежая газета, ', '(ОТ)ТОГО', ' движения его были немного скованными.']\n",
      "[4.4069576e-08, 4.3939417e-06, 0.00081084564] 1 [2.544709e-05] 1\n",
      "4.4069576432548274e-08\n",
      "['(НЕ)СМОТРЯ', ' на то что отец всегда был настроен ', '(ПОЛУ)ШУТЛИВО', ', он был человек отнюдь не легкомысленный.']\n",
      "[0.00021873468] 1 [7.7305293e-07, 8.059144e-06, 0.00039057943] 1\n",
      "7.73052931890561e-07\n",
      "несмотряполушутливо\n",
      "['несмотряполушутливо', 'полушутливонесмотря']\n",
      "Task # 13\n",
      "['Причиной выбрасывания китов на берег могут быть гидролокаторы военных, достаточно мощные, ', 'ЧТО(БЫ)', ' проникнуть ', '(В)ГЛУБЬ', ' океана и напугать животных.']\n",
      "[0.9747608] 1 [0.34955] 1\n",
      "0.3495500087738037\n",
      "['Недолго пройдя в темноте, Костя понял, что ', '(СО)ВСЕМ', ' сбился с пути, наверно, ', 'ТО(ЖЕ)', ' понял и командир.']\n",
      "[0.00056440855] 1 [0.00035654698] 1\n",
      "0.0003565469814930111\n",
      "['Новобранцев до принятия присяги не полагалось отпускать в город ', '(ПО)ОДИНОЧКЕ', ', но инструктор, ', '(В)ВИДУ', ' моего необычайного успеха по словесности, сделал для меня исключение.']\n",
      "[6.987365e-05] 1 [0.36560205] 1\n",
      "6.987364758970216e-05\n",
      "['Никита сказал, ', 'ЧТО(БЫ)', ' мы шли ', '(ПО)ДВОЕ', '.']\n",
      "[0.21487334] 1 [1.95791e-05, 3.1421438e-05] 1\n",
      "1.957909989869222e-05\n",
      "чтобывглубь\n",
      "['поодиночкеввиду', 'ввидупоодиночке']\n",
      "Task # 14\n",
      "['Причиной выбрасывания китов на берег могут быть гидролокаторы военных, достаточно мощные, ', 'ЧТО(БЫ)', ' проникнуть ', '(В)ГЛУБЬ', ' океана и напугать животных.']\n",
      "[0.9747608] 1 [0.34955] 1\n",
      "0.3495500087738037\n",
      "['Недолго пройдя в темноте, Костя понял, что ', '(СО)ВСЕМ', ' сбился с пути, наверно, ', 'ТО(ЖЕ)', ' понял и командир.']\n",
      "[0.00056440855] 1 [0.00035654698] 1\n",
      "0.0003565469814930111\n",
      "['Новобранцев до принятия присяги не полагалось отпускать в город ', '(ПО)ОДИНОЧКЕ', ', но инструктор, ', '(В)ВИДУ', ' моего необычайного успеха по словесности, сделал для меня исключение.']\n",
      "[6.987365e-05] 1 [0.36560205] 1\n",
      "6.987364758970216e-05\n",
      "['Никита сказал, ', 'ЧТО(БЫ)', ' мы шли ', '(ПО)ДВОЕ', '.']\n",
      "[0.21487334] 1 [1.95791e-05, 3.1421438e-05] 1\n",
      "1.957909989869222e-05\n",
      "чтобывглубь\n",
      "['поодиночкеввиду', 'ввидупоодиночке']\n",
      "Task # 15\n",
      "['Петр I хотел, ', 'ЧТО(БЫ)', ' Россия, получившая выход на Балтику, стала ', 'ТАК(ЖЕ)', ' сильной тихоокеанской державой.']\n",
      "[0.98951894] 1 [0.00041270914] 1\n",
      "0.0004127091378904879\n",
      "['(ВО)ВРЕМЯ', ' плавания экспедиция открыла новые острова и прошла пролив, названный ', '(В)ПОСЛЕДСТВИИ', ' Беринговым.']\n",
      "[1.1611938e-08] 1 [0.5389414] 1\n",
      "1.1611938077749073e-08\n",
      "['В ', 'ТО(ЖЕ)', ' самое время в Петербурге уже подготавливали новую экспедицию, которой, кроме плавания в Тихом океане, предстояли и ', 'СО(ВСЕМ)', ' иные маршруты.']\n",
      "[0.0019605013] 1 [0.41000074] 1\n",
      "0.0019605013076215982\n",
      "тожесовсем\n",
      "['чтобытакже', 'такжечтобы']\n",
      "Task # 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Теперь, даже ', '(НЕ)СМОТРЯ', ' на седину, морщины и очки, его ', '(НА)ЧИСТО', ' лишённое эмоций лицо кажется прекрасным.']\n",
      "[0.98087686] 1 [4.838296e-07, 0.0001007038] 1\n",
      "4.838295808440307e-07\n",
      "['Илье Антонычу наскучило носить ружьё ', '(ПОД)МЫШКОЙ', ', ', '(ПО)ЭТОМУ', ' он перекинул его на плечо.']\n",
      "[7.894238e-06, 0.00012953689, 0.003978688] 1 [0.00182377] 1\n",
      "7.894237569416873e-06\n",
      "['(НА)КОНЕЦ', ' прошла неделя, а комната всё ', 'ТАК(ЖЕ)', ' была заперта.']\n",
      "[9.930327e-07] 1 [0.0006739774] 1\n",
      "9.930326996254735e-07\n",
      "подмышкойпоэтому\n",
      "['несмотряначисто', 'начистонесмотря']\n",
      "Task # 17\n",
      "подальшевмиг\n",
      "['подальшевмиг', 'вмигподальше']\n",
      "Task # 18\n",
      "['ТО(ЖЕ)', ' тихое мерцание зеленоватого прозрачного неба, ', 'ТАК(ЖЕ)', ' тянет с реки холодной влагой.']\n",
      "[1.4368223e-07] 1 [7.5075775e-05] 1\n",
      "1.4368222878147208e-07\n",
      "['(ПОЛ)ДНЯ', ' ушло на сборы и подготовку к выступлению, ', '(ПРИ)ЧЁМ', ' оказалось, что ещё далеко не всё готово.']\n",
      "[6.3048516e-05, 1.6333253e-05] 1 [0.0010269227] 1\n",
      "1.6333253370248713e-05\n",
      "полдняпричём\n",
      "['полдняпричём', 'причёмполдня', 'полдняпричем', 'причемполдня']\n",
      "Task # 19\n",
      "поистинетакже\n",
      "['поистинетакже', 'такжепоистине']\n",
      "Task # 20\n",
      "['В дальнем конце коридора стояло странное сооружение, ', '(НА)ПОДОБИЕ', ' огромной рельсы, уходящей под углом ', '(В)ВЕРХ', '.']\n",
      "[0.07216842] 1 [0.047921672] 1\n",
      "0.04792167246341705\n",
      "['Всё ', 'ТАК(ЖЕ)', ' горела сальная свеча на столе, росли тихие герани на подоконниках, тикали часы, ', '(ПРИ)ЧЁМ', ' звук их с годами совсем не изменился.']\n",
      "[0.00063852995] 1 [0.0128590185] 1\n",
      "0.0006385299493558705\n",
      "наподобиевверх\n",
      "['наподобиевверх', 'вверхнаподобие']\n",
      "Task # 21\n",
      "['Дизайнеры обратили внимание ', '(НА)ПОДОБИЕ', ' планировок соседних комнат, которые должны были ', '(В)ПОСЛЕДСТВИИ', ' преобразиться в сказочные спальни для близнецов.']\n",
      "[6.5564636e-06] 1 [0.23068413] 1\n",
      "6.5564636315684766e-06\n",
      "['Как только я ступил за порог, он ', '(ТОТ)ЧАС', ' же меня окликнул и помахал на прощание рукой, я сделал ', '(ТО)ЖЕ', ', улыбнувшись в ответ.']\n",
      "[0.04935985] 1 [0.0001224607] 1\n",
      "0.0001224606967298314\n",
      "['(НЕ)СМОТРЯ', ' на долгую дружбу, Агафонов ударил его между лопаток, он ', '(ЗА)ТО', ' еще долго на него злился.']\n",
      "[0.0006065199] 1 [4.9725342e-05] 1\n",
      "4.9725342250894755e-05\n",
      "['Он периодически думал, ', 'ЧТО(БЫ)', ' сделать, ', 'ЧТО(БЫ)', ' избавиться от хандры.']\n",
      "[0.00046088806] 1 [0.62825227] 1\n",
      "0.00046088805538602173\n",
      "['(В)СЛЕДСТВИЕ', ' затяжного кризиса утечка кадров достигла критического уровня, ', '(В)СЛЕД', ' за чем компания перестала существовать.']\n",
      "[3.908298e-05] 1 [0.97093767] 1\n",
      "3.908298094756901e-05\n",
      "чтобычтобы\n",
      "['вследствиевслед', 'вследвследствие']\n",
      "Task # 22\n",
      "['Максимка, ', '(ЧТО)БЫ', ' ни говорили все вокруг, верил в успех, и ', '(ПО)НЕМНОГУ', ' дело пошло.']\n",
      "[0.00010344975] 1 [0.00017759876] 1\n",
      "0.0001034497472574003\n",
      "['Подошедший к костру ', '(С)НАЧАЛА', ' застенчиво постоял, а потом придвинулся к огню ', '(ПО)БЛИЖЕ', '.']\n",
      "[0.031601578] 1 [0.0025600425] 1\n",
      "0.002560042543336749\n",
      "['Погода, как показалось Наташе, ', 'БУД(ТО)', ' начала меняться, снег словно перестал валить сплошной стеной – но нет: утром было всё ', 'ТО(ЖЕ)', '.']\n",
      "[0.000584513] 1 [0.0020889747] 1\n",
      "0.0005845130071975291\n",
      "сначалапоближе\n",
      "['сначалапоближе', 'поближесначала']\n",
      "Task # 23\n",
      "['(В)ПОСЛЕДСТВИИ', ' учёные установили, что магний играет важную роль в регуляции уровня калия в организме, а ', 'ТАК(ЖЕ)', ' регулирует работу надпочечников.']\n",
      "[3.0691674e-05] 1 [0.9852594] 1\n",
      "3.0691673600813374e-05\n",
      "['Физические свойства межзвёздного газа существенно зависят ', '(ОТ)ТОГО', ', находится ли он в сравнительной близости от горячих звёзд или, ', '(НА)ОБОРОТ', ', достаточно удалён от них.']\n",
      "[0.14381863] 1 [0.6937293] 1\n",
      "0.14381863176822662\n",
      "оттогонаоборот\n",
      "['впоследствиитакже', 'такжевпоследствии']\n",
      "Task # 24\n",
      "тожепоэтому\n",
      "['тожепоэтому', 'поэтомутоже']\n",
      "Task # 25\n",
      "насчёттакже\n",
      "['насчёттакже', 'такженасчёт']\n",
      "Task # 26\n",
      "['Рисунки известных мастеров графики ', '(ПО)ВСЮДУ', ' в музеях ', 'ТАК(ЖЕ)', ' бережно хранятся, как и картины живописцев.']\n",
      "[0.00024184713] 1 [0.0015113261] 1\n",
      "0.00024184712674468756\n",
      "['Отстегнув ремни, они надели ', '(ТЕРМО)КОСТЮМЫ', ', потому что, ', '(НЕ)СМОТРЯ', ' на полдень, было холодно.']\n",
      "[1.3595321e-05, 3.8330595e-06, 9.173712e-05, 0.008049912] 1 [0.77876353] 1\n",
      "3.8330595089064445e-06\n",
      "['(И)ТАК', ', я очень расстроена: в вашем сочинении ', '(ПОЛНЫМ)ПОЛНО', ' ошибок.']\n",
      "[1.4815321e-05, 3.700437e-05] 1 [9.722077e-06, 7.109795e-07, 0.00049743784] 1\n",
      "7.109795205906266e-07\n",
      "термокостюмынесмотря\n",
      "['термокостюмынесмотря', 'несмотрятермокостюмы']\n",
      "Task # 27\n",
      "полшкафаполупустой\n",
      "['полшкафаполупустой', 'полупустойполшкафа']\n",
      "Task # 28\n",
      "['Во всём городе не было людей, настроенных ', 'ТАК(ЖЕ)', ' спокойно и в ', 'ТО(ЖЕ)', ' время торжественно, как эти двое.']\n",
      "[0.00060751877] 1 [0.0044929464] 1\n",
      "0.0006075187702663243\n",
      "['(С)НАЧАЛА', ' лучше сделать самые трудные уроки, ', '(ПО)ТОМУ', ' что их выполнение потребует больше времени.']\n",
      "[2.3384727e-07] 1 [0.93434155] 1\n",
      "2.3384727398934047e-07\n",
      "такжетоже\n",
      "['сначалапотому', 'потомусначала']\n",
      "Task # 29\n",
      "подальшевмиг\n",
      "['подальшевмиг', 'вмигподальше']\n",
      "Task # 30\n",
      "вправесгоряча\n",
      "['вправесгоряча', 'сгорячавправе']\n",
      "Task # 31\n",
      "такжебы\n",
      "['такжечтобы', 'чтобытакже']\n",
      "Task # 32\n",
      "наконецзачем\n",
      "['наконецзачем', 'зачемнаконец']\n",
      "Task # 33\n",
      "['Я заказал себе обед ', '(НА)ВЫНОС', ' и попросил сделать кофе ', '(ПО)КРЕПЧЕ', '.']\n",
      "[4.181224e-05, 2.1415183e-06] 1 [7.5426315e-06, 5.1617812e-06, 0.000208402] 1\n",
      "2.141518280041055e-06\n",
      "['(В)СЛЕД', ' ', '(ЗА)ТЕМ', ' показался на горизонте силуэт всадника.']\n",
      "[3.4743036e-06] 1 [0.0014381998] 1\n",
      "3.474303639450227e-06\n",
      "['Когда все ', '(В)КОНЕЦ', ' обессилели от изнурительной работы, нас выстроили в колонну ', '(ПО)ДВОЕ', ' и повели в казармы.']\n",
      "[1.473189e-06, 7.4876916e-06] 1 [1.4658801e-05, 5.9447825e-06] 1\n",
      "1.473188945055881e-06\n",
      "навыноспокрепче\n",
      "['навыноспокрепче', 'покрепченавынос']\n",
      "Task # 34\n",
      "['(С)УТРА', ' шёл дождь, ', '(ЗА)ТО', ' сейчас над нами чистое, блестящее небо.']\n",
      "[8.3885584e-07, 0.00016412005] 1 [0.0011648958] 1\n",
      "8.38855839901953e-07\n",
      "['Дорожка идёт ', '(С)НАЧАЛА', ' берегом, а потом уходит ', '(В)ГЛУБЬ', ' дремучего соснового бора.']\n",
      "[0.00014192991] 1 [0.34355405] 1\n",
      "0.0001419299078406766\n",
      "['Готические здания отличаются обилием ажурных, ', '(НА)ПОДОБИЕ', ' кружев, украшений, скульптур, орнаментов, ', '(ПО)ЭТОМУ', ' они производят впечатление легкости и воздушности.']\n",
      "[3.5222587e-05] 1 [0.04365489] 1\n",
      "3.5222587030148134e-05\n",
      "сутразато\n",
      "['наподобиепоэтому', 'поэтомунаподобие']\n",
      "Task # 35\n",
      "['Приходилось следить ', '(ЗА)ТЕМ', ', ', 'ЧТО(БЫ)', ' выдерживать определённую дистанцию.']\n",
      "[0.00038195777] 1 [0.65782017] 1\n",
      "0.00038195776869542897\n",
      "['ЧТО(БЫ)', ' почитать, ', 'ЧТО(БЫ)', ' больше знать об истории Рима.']\n",
      "[0.0003493781] 1 [0.20546934] 1\n",
      "0.000349378096871078\n",
      "['(ЗА)ЧЕМ', ' пойдёшь, ', 'ТО(И)', ' найдёшь.']\n",
      "[3.7872153e-06] 1 [0.10097424, 0.00031290762] 1\n",
      "3.787215291595203e-06\n",
      "затемчтобы\n",
      "['отчегооттого', 'оттогоотчего']\n",
      "Task # 36\n",
      "['Я ', 'ТО(ЖЕ)', ', как и отец, верил в нашу идею, ', '(ПРИ)ЧЁМ', ' не только разумом, но и сердцем.']\n",
      "[0.04080367] 1 [0.0077486904] 1\n",
      "0.0077486904338002205\n",
      "['(ЗА)ТЕМ', ' инструктор объяснил мне, что без специального снаряжения ', '(В)ГЛУБЬ', ' моря опускаться опасно.']\n",
      "[6.61081e-05] 1 [0.009665489] 1\n",
      "6.610809941776097e-05\n",
      "['О том, ', '(НА)СКОЛЬКО', ' тяжело было Кате в тот момент, Арсений узнал позже, ', '(В)НАЧАЛЕ', ' следующего года.']\n",
      "[0.20999853] 1 [1.2794208e-06] 1\n",
      "1.2794207577826455e-06\n",
      "['Поверните ', '(В)ЛЕВО', ', пройдите по коридору с множеством кабинетов и, ', 'ЧТО(БЫ)', ' вы ни услышали из-за дверей, не останавливайтесь, а идите прямо.']\n",
      "[0.000112347385] 1 [0.10044811] 1\n",
      "0.00011234738485654816\n",
      "тожепричём\n",
      "['тожепричём', 'причёмтоже']\n",
      "Task # 37\n",
      "['А небо в те дни льёт на землю ласкающий свет, и прозрачная голубизна его бывает притягательна – не ', '(ОТ)ТОГО', ' ли и стар и млад так ', '(ПО)ДОЛГУ', ' смотрят на небо.']\n",
      "[0.0005272694] 1 [0.00010825274] 1\n",
      "0.00010825273784575984\n",
      "['ТАК(ЖЕ)', ' было и в прошлый раз, три месяца тому назад, когда она с ним разговаривала, а потом речь её прервалась на ', '(ПОЛУ)СЛОВЕ', '.']\n",
      "[5.522411e-07] 1 [0.000115444556, 1.5497511e-05, 0.04297667] 1\n",
      "5.52241090190364e-07\n",
      "['Но он ничего не сделал, ', '(ПО)ТОМУ', ' что и не мог ничего сделать, просто не было у него ничего такого затаённого, ', 'ЧТО(Б)', ' он мог вытащить наружу.']\n",
      "[0.80798334] 1 [0.0022322775] 1\n",
      "0.0022322775330394506\n",
      "потомучтоб\n",
      "['оттогоподолгу', 'подолгуоттого']\n",
      "Task # 38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Нет, судите наш народ не ', '(ПО)ТОМУ', ', что он есть, а ', '(ПО)ТОМУ', ', чем он желал бы стать.']\n",
      "[0.461019] 1 [0.046049424] 1\n",
      "0.04604942351579666\n",
      "['(В)ПОСЛЕДСТВИИ', ' речь автора была проста, ', '(ПРИ)ЧЁМ', ' выразительна.']\n",
      "[1.2495465e-07] 1 [6.4830434e-05] 1\n",
      "1.2495465284700913e-07\n",
      "потомупотому\n",
      "['впоследствиипричём', 'причёмвпоследствии']\n",
      "Task # 39\n",
      "['Мы отправили посылку ', '(В)НАЧАЛЕ', ' месяца, и она пришла ', '(ВО)ВРЕМЯ', '.']\n",
      "[7.671429e-05] 1 [0.0683443] 1\n",
      "7.67142919357866e-05\n",
      "['Во ', 'ЧТО(БЫ)', ' нам поиграть, ', 'ЧТО(БЫ)', ' весело провести время.']\n",
      "[6.4696e-06] 1 [0.5206495] 1\n",
      "6.469600066338899e-06\n",
      "['Идите ', '(В)НИЗ', ' по склону, там и будет ', '(АВТО)СТОЯНКА', '.']\n",
      "[0.54001874] 1 [1.2882702e-05, 0.023408066] 1\n",
      "1.2882702321803663e-05\n",
      "внизавтостоянка\n",
      "['внизавтостоянка', 'автостоянкавниз']\n",
      "Task # 40\n",
      "полгодазамуж\n",
      "['полгодазамуж', 'замужполгода']\n",
      "Task # 41\n",
      "['«И имейте ', '(В)ВИДУ', ': ', 'ЧТО(БЫ)', ' там ещё вы ни придумали, мне всё станет известно.']\n",
      "[0.023901682] 1 [0.0006255048] 1\n",
      "0.0006255048210732639\n",
      "['На подносах лежали камни ', '(НА)ПОДОБИЕ', ' кирпичей с золотыми вензелями императора и его супруги, а ', 'ТАК(ЖЕ)', ' монеты нового чекана.']\n",
      "[0.0014279127] 1 [0.9954999] 1\n",
      "0.0014279127353802323\n",
      "['Только у дверей сидел ', '(ОРДЕНО)НОСЕЦ', ' Решетов, читая книгу, и ', '(ПО)ТОМУ', ', как он увлёкся, было видно, что это его собственный роман.']\n",
      "[7.452907e-06, 6.299354e-06, 0.0020584583] 1 [0.040310822] 1\n",
      "6.299354026850779e-06\n",
      "['(В)СЛЕД', ' ', '(ЗА)ТЕМ', ', откуда ни возьмись, у чугунной решётки вспыхнул огонёчек и стал приближаться к веранде.']\n",
      "[9.773087e-07] 1 [0.007318502] 1\n",
      "9.773086731001968e-07\n",
      "орденоносецпотому\n",
      "['наподобиетакже', 'такженаподобие']\n",
      "Task # 42\n",
      "['(С)НАЧАЛА', ' мы не собирались идти ', '(НА)ВСТРЕЧУ', ' выпускников.']\n",
      "[1.3445776e-06] 1 [0.0031220359] 1\n",
      "1.3445776403386844e-06\n",
      "['Сосед каждый день приходил к нам ', '(ВО)ВРЕМЯ', ' ужина и всегда произносил одно и ', 'ТО(ЖЕ)', ' приветствие.']\n",
      "[1.8684119e-06] 1 [0.16368341] 1\n",
      "1.868411914074386e-06\n",
      "['(И)ТАК', ', почему ты не смог прийти ', '(ВО)ВРЕМЯ', '.']\n",
      "[4.2804334e-07, 1.650073e-05] 1 [0.0110199815] 1\n",
      "4.28043335887196e-07\n",
      "итаквовремя\n",
      "['итаквовремя', 'вовремяитак']\n",
      "Task # 43\n",
      "['ЧТО(БЫ)', ' быть счастливым, нужно стремиться к успеху и в ', 'ТО(ЖЕ)', ' время необходимо учиться благородству по отношению к людям.']\n",
      "[0.00024323654] 1 [0.04193481] 1\n",
      "0.00024323654361069202\n",
      "['Иван ', '(СО)ВСЕМ', ' не умел спорить и никогда не шёл ', '(НА)ПЕРЕКОР', ' общественному мнению.']\n",
      "[8.5839325e-05] 1 [7.2253795e-05, 5.026883e-05, 0.00018247312] 1\n",
      "5.026883081882261e-05\n",
      "['(И)ТАК', ', дети доказали, что хорошая учёба приносит удовлетворение, учитель говорил ', 'ТО(ЖЕ)', ' самое.']\n",
      "[2.2234092e-06, 4.0577015e-06] 1 [0.33838257] 1\n",
      "2.2234091829886893e-06\n",
      "чтобытоже\n",
      "['совсемнаперекор', 'наперекорсовсем']\n",
      "Task # 44\n",
      "['Собранные растения перед сушкой следует очистить от земли, а ', 'ТАК(ЖЕ)', ' от посторонних примесей, ', '(ЗА)ТЕМ', ' разложить их на подстилке.']\n",
      "[0.47305277] 1 [0.108522765] 1\n",
      "0.10852276533842087\n",
      "['Мои спутники ', 'ТО(ЖЕ)', ' осматривали берег, но ', '(В)ВИДУ', ' имели совсем другое.']\n",
      "[0.037706528] 1 [0.0009434503] 1\n",
      "0.0009434503153897822\n",
      "['(ВО)ВРЕМЯ', ' занятия все задания мы сделали ', '(ВО)ВРЕМЯ', '.']\n",
      "[3.2508342e-07] 1 [0.009642551] 1\n",
      "3.2508341973880306e-07\n",
      "такжезатем\n",
      "['такжезатем', 'затемтакже']\n",
      "Task # 45\n",
      "['ЧТО(БЫ)', ' ни случилось, хочется, ', 'ЧТО(БЫ)', ' все остались друзьями.']\n",
      "[3.906388e-05] 1 [0.97098184] 1\n",
      "3.906388155883178e-05\n",
      "['Убранство комнат ', 'ТАК(ЖЕ)', ' не отличалось особым комфортом; даже полы были некрашеные, ', 'ЗА(ТО)', ' всё блистало чистотой.']\n",
      "[0.07156747] 1 [0.04074681] 1\n",
      "0.04074681177735329\n",
      "такжезато\n",
      "['такжезато', 'затотакже']\n",
      "Task # 46\n",
      "['Я спросил Галю, что она имела ', '(В)ВИДУ', ', когда говорила, что дальше нам придётся действовать ', '(ПО)ОДИНОЧКЕ', '.']\n",
      "[0.061277434] 1 [0.00020563795] 1\n",
      "0.0002056379453279078\n",
      "['Малик ', 'ТО(ЖЕ)', ' был спортсменом, ', '(ПРИ)ЧЁМ', ' хорошо известным.']\n",
      "[0.014456339] 1 [0.00054515817] 1\n",
      "0.0005451581673696637\n",
      "['Я отплыл ещё дальше ', '(В)ГЛУБЬ', ' протоки и заметил лежащее в воде толстое бревно, треснутое посередине ', '(НА)ДВОЕ', '.']\n",
      "[0.03226442] 1 [8.4807376e-05] 1\n",
      "8.48073759698309e-05\n",
      "['(НА)СЧЁТ', ' денег можете не беспокоиться: ', 'ЧТО(БЫ)', ' ни случилось, нас есть кому поддержать.']\n",
      "[4.7593916e-05] 1 [0.029399496] 1\n",
      "4.759391595143825e-05\n",
      "тожепричём\n",
      "['тожепричём', 'причёмтоже']\n",
      "Task # 47\n",
      "['В ', 'ТО(ЖЕ)', ' время купец Смельков был тип могучего русского человека, который ', '(В)СЛЕДСТВИЕ', ' своей доверчивости пал жертвою обмана.']\n",
      "[0.0011300575] 1 [0.04188191] 1\n",
      "0.0011300574988126755\n",
      "['(ПО)ТОМУ', ', быть может, что Женя провела со мной весь день с утра до вечера, я почувствовал, что без неё мне как ', 'БУД(ТО)', ' скучно.']\n",
      "[1.6397247e-05] 1 [0.2812833] 1\n",
      "1.639724723645486e-05\n",
      "['После встречи с Варенькой Оля попросила: «Научите меня, ', 'ЧТО(БЫ)', ' я поступила точно ', 'ТАК(ЖЕ)', '».']\n",
      "[0.65692633] 1 [0.00039229155] 1\n",
      "0.0003922915493603796\n",
      "тожевследствие\n",
      "['потомубудто', 'будтопотому']\n",
      "Task # 48\n",
      "['(В)ПОСЛЕДСТВИИ', ' выяснилось ', 'ТАК(ЖЕ)', ', что Иван собирался переехать к матери в деревню.']\n",
      "[4.8819285e-05] 1 [0.16790783] 1\n",
      "4.881928543909453e-05\n",
      "['Егорка пошёл ', '(В)ГЛУБЬ', ' тёмного чулана, ', 'ЧТО(БЫ)', ' отыскать ящик.']\n",
      "[0.00814556] 1 [0.8459071] 1\n",
      "0.008145559579133987\n",
      "вглубьчтобы\n",
      "['впоследствиитакже', 'такжевпоследствии']\n",
      "Task # 49\n",
      "полгодазамуж\n",
      "['полгодазамуж', 'замужполгода']\n",
      "Task # 50\n",
      "['Я целый месяц жил здесь только ', '(ЗА)ТЕМ', ', ', '(ЧТО)БЫ', ' дождаться удобного случая.']\n",
      "[0.00022361954] 1 [0.80897766] 1\n",
      "0.00022361954324878752\n",
      "['(И)ТАК', ', всё кончено, ', '(И)ТАК', ' кончается каждый раз.']\n",
      "[3.1939493e-05, 2.9403256e-05] 1 [1.3738494e-05, 1.999933e-05] 1\n",
      "1.3738494089921005e-05\n",
      "затемчтобы\n",
      "['затемчтобы', 'чтобызатем']\n",
      "Task # 51\n",
      "['Берись ', 'ЗА(ТО)', ', к чему ты сроден, коль хочешь, ', 'ЧТО(Б)', ' в делах успешный был конец.']\n",
      "[7.1553154e-06] 1 [0.08909878] 1\n",
      "7.155315415730001e-06\n",
      "['Анна готова была много работать, ', 'ЧТО(БЫ)', ' не оставаться ', '(НА)ЕДИНЕ', ' с грустными мыслями.']\n",
      "[0.3058445] 1 [0.64048684] 1\n",
      "0.3058444857597351\n",
      "чтобынаедине\n",
      "чтобынаедине\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for i, task in enumerate(tasks):\n",
    "    print(f\"Task # {i}\")\n",
    "    task = task[\"tasks\"][0]\n",
    "    pred = solver_14(task)\n",
    "    print(pred)\n",
    "    if \"correct\" in task[\"solution\"]:\n",
    "        answer = task[\"solution\"][\"correct\"]\n",
    "        print(answer)\n",
    "        scores.append(answer == pred)\n",
    "    else:\n",
    "        answer = task[\"solution\"][\"correct_variants\"]\n",
    "        print(answer)\n",
    "        scores.append(any([pred == t for t in answer]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5961538461538461"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
